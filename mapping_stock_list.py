import pandas as pd
import re
from io import StringIO
from datetime import datetime
from supabase import create_client, Client
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬)
# NOTE: secrets.txt ëŒ€ì‹  .env íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” í‘œì¤€ì ì…ë‹ˆë‹¤.
load_dotenv()

# ----------------------------------------------------
# 1. Supabase ì—°ê²° ì„¤ì •
# ----------------------------------------------------
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("FATAL ERROR: Supabase URL ë˜ëŠ” Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    exit()

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
print("Supabase ì—°ê²° ì„±ê³µ!")


# --- 1. Supabase ì—°ë™ í—¬í¼ í•¨ìˆ˜ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš© ë° accounts ì¶”ê°€) ---
def get_asset_lookup():
    """Supabaseì—ì„œ 'assets' í…Œì´ë¸”ì„ ì¡°íšŒí•˜ì—¬ ì¢…ëª©ëª…(name_kr)ê³¼ IDë¥¼ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    try:
        response = supabase.table('assets').select('id, name_kr').execute()
        asset_map = {item['name_kr']: item['id'] for item in response.data}
        print(f"âœ… assets í…Œì´ë¸”ì—ì„œ {len(asset_map)}ê±´ì˜ ìì‚° ID ë§¤í•‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
        return asset_map
    except Exception as e:
        print(f"âŒ assets í…Œì´ë¸” ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {}

def get_account_lookup():
    """Supabaseì—ì„œ 'accounts' í…Œì´ë¸”ì„ ì¡°íšŒí•˜ì—¬ ê³„ì¢Œëª…(name)ê³¼ IDë¥¼ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # accounts í…Œì´ë¸”ì—ì„œ nameê³¼ id ì»¬ëŸ¼ë§Œ ì¡°íšŒ
        response = supabase.table('accounts').select('id, name').execute()
        account_map = {item['name']: item['id'] for item in response.data}
        print(f"âœ… accounts í…Œì´ë¸”ì—ì„œ {len(account_map)}ê±´ì˜ ê³„ì¢Œ ID ë§¤í•‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
        return account_map
    except Exception as e:
        print(f"âŒ accounts í…Œì´ë¸” ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {}
    

# --- 2. ë°ì´í„° í´ë¦¬ë‹ ë° íŒŒì‹± í—¬í¼ í•¨ìˆ˜ ---
def clean_currency_string(value):
    """'1,234,567ì›', '$123.45', '123' í˜•íƒœì˜ ë¬¸ìì—´ì„ floatìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if pd.isna(value) or value in (None, ''):
        return 0.0

    # ë”°ì˜´í‘œ ì œê±° (CSV íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€)
    value = str(value).strip().replace('"', '').replace("'", "")
    
    # ìˆ«ìì™€ ì†Œìˆ˜ì ë§Œ ë‚¨ê¸°ë„ë¡ í†µí™” ê¸°í˜¸, ì½¤ë§ˆ, 'ì›' ë“±ì„ ì œê±°
    cleaned_value = re.sub(r'[â‚©$,%a-zA-Z\s]', '', value)
    
    try:
        return float(cleaned_value)
    except ValueError:
        return 0.0

def parse_csv_content(csv_content):
    """
    ë¹„í‘œì¤€ CSV í…ìŠ¤íŠ¸ì—ì„œ ìì‚° ìƒì„¸ ëª©ë¡ ë¶€ë¶„ë§Œ íŒŒì‹±í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ìƒì„¸ ëª©ë¡ í—¤ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì‹œì‘ ì§€ì ì„ ì°¾ìŠµë‹ˆë‹¤.
    data_start_line = csv_content.find(',,ì¦ê¶Œì‚¬,í‹°ì»¤(ì½”ë“œ),ì¢…ëª©ëª…,ì”ê³ ìˆ˜ëŸ‰')
    if data_start_line == -1:
        raise ValueError("CSV íŒŒì¼ì—ì„œ ìƒì„¸ ë°ì´í„° ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ìƒì„¸ ë°ì´í„° ì„¹ì…˜ë§Œ ì¶”ì¶œ
    detail_section = csv_content[data_start_line:].split('\n')
    
    # ì¢…ëª©ë²ˆí˜¸(í‹°ì»¤) ì •ë³´ í…Œì´ë¸” ì§ì „ê¹Œì§€ì˜ ìœ íš¨ ë°ì´í„°ë§Œ í•„í„°ë§ (ë¶ˆí•„ìš”í•œ ê³µë°± í–‰, í•©ê³„ í–‰ ì œê±°)
    data_lines = []
    
    # 40ë²ˆì§¸ ë¼ì¸ ì´í›„ë¶€í„° ì¢…ëª© ìƒì„¸ì •ë³´ ë¼ì¸ë“¤ë§Œ ì¶”ì¶œ
    for i, line in enumerate(detail_section):
        # 1. í—¤ë” ë¼ì¸ ì œê±°
        if i == 0: continue
        
        # 2. ë‹¤ìŒ ì„¹ì…˜ (ì¢…ëª©ë²ˆí˜¸/í‰ê· ë‹¨ê°€) ì‹œì‘ ì „ê¹Œì§€ (ë¹„ê³  í•„ë“œê°€ ì•„ë‹Œ ë¹ˆ ì¤„ì´ ë‚˜ì˜¤ë©´ ì¢…ë£Œ)
        if line.startswith(',,,ì¢…ëª©ë²ˆí˜¸') or line.strip() == '':
            break
            
        # 3. ë°ì´í„°ê°€ ë“¤ì–´ìˆì§€ ì•Šì€ ë¼ì¸ ì œê±°
        if len(line.strip().replace(',', '')) < 10:
             continue
        
        data_lines.append(line.strip())

    # ì¶”ì¶œëœ ë°ì´í„°ë¥¼ StringIO ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ Pandas read_csvë¡œ ì²˜ë¦¬
    # ì»¬ëŸ¼ì€ 15ê°œ (ì„ í–‰ 2ê°œ ë¹ˆì¹¸ + 13ê°œ ë°ì´í„° ì»¬ëŸ¼)
    csv_data = "\n".join(data_lines)
    
    # ì»¬ëŸ¼ëª… ì„ì‹œ ì§€ì • (ì´í›„ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ)
    temp_df = pd.read_csv(StringIO(csv_data), header=None, skiprows=0)

    # ì—‘ì…€ ì‹œíŠ¸ ê¸°ë°˜ì˜ ì»¬ëŸ¼ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
    # A=0, B=1, C=2, D=3, E=4, F=5, G=6, H=7, I=8, J=9, K=10, L=11, M=12, N=13, O=14
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ ë° ìƒˆ ì»¬ëŸ¼ëª… ë¶€ì—¬
    df = temp_df.iloc[:, [2, 3, 4, 5, 6, 7, 10, 11]].copy()
    df.columns = [
        'account_name', 'ticker', 'asset_name', 'quantity', 
        'current_price', 'avg_purchase_price', 'valuation_amount', 'purchase_amount'
    ]
    
    # 'account_name'ì´ ë¹„ì–´ìˆëŠ” í–‰ ì œê±° (ì”ê³  ìƒì„¸ê°€ ì•„ë‹Œ ê¸°íƒ€ í—¤ë” í–‰ì¼ ìˆ˜ ìˆìŒ)
    df = df.dropna(subset=['account_name'])
    
    return df

# --- 3. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---

def prepare_data_for_supabase(file_content):
    # 1. DB ë§¤í•‘ ë°ì´í„° ë¡œë“œ
    asset_lookup_map = get_asset_lookup()
    account_lookup_map = get_account_lookup()
    
    if not account_lookup_map:
        print("ğŸš¨ accounts í…Œì´ë¸” ë§¤í•‘ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. DB ì—°ê²° ë° ë°ì´í„° ì‚½ì…ì„ í™•ì¸í•˜ì„¸ìš”.")
        return pd.DataFrame()

    # 2. CSV íŒŒì¼ íŒŒì‹±
    print("â³ CSV ë°ì´í„° íŒŒì‹± ì‹œì‘...")
    df = parse_csv_content(file_content)
    print(f"âœ… ì´ {len(df)}ê±´ì˜ ìì‚° ìƒì„¸ ë°ì´í„° íŒŒì‹± ì™„ë£Œ.")

    # 3. ë°ì´í„° í´ë¦¬ë‹
    print("â³ ë°ì´í„° í´ë¦¬ë‹ ë° ë³€í™˜ ì‹œì‘...")
    
    # í†µí™” ë¬¸ìì—´ì„ ìˆ«ì(float)ë¡œ ë³€í™˜
    currency_cols = [
        'current_price', 'avg_purchase_price', 'valuation_amount', 'purchase_amount'
    ]
    for col in currency_cols:
        df[col] = df[col].apply(clean_currency_string)

    # ì”ê³ ìˆ˜ëŸ‰(quantity)ë„ ìˆ«ìë¡œ ë³€í™˜
    df['quantity'] = df['quantity'].fillna(0).apply(clean_currency_string)
    
    # 4. ID ë§¤í•‘ ì ìš©
    df['account_id'] = df['account_name'].map(account_lookup_map)
    df['asset_id'] = df['asset_name'].map(asset_lookup_map)
    
    # 5. íŠ¹ìˆ˜ í•­ëª© ì²˜ë¦¬ (Asset IDê°€ ì—†ëŠ” í˜„ê¸ˆ/í€ë“œ ë“±)
    # - asset_idê°€ NaNì´ì§€ë§Œ valuation_amountê°€ 0ì´ ì•„ë‹Œ ê²½ìš°:
    #   í•´ë‹¹ ìì‚°(ì¢…ëª©ëª…)ì„ assets í…Œì´ë¸”ì— ë¨¼ì € ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
    #   ì—¬ê¸°ì„œëŠ” ë¯¸ë“±ë¡ ìì‚° ëª©ë¡ì„ ì¶œë ¥í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ DB ì¶”ê°€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
    missing_assets = df[df['asset_id'].isna() & (df['valuation_amount'] > 0)]['asset_name'].unique()
    
    if len(missing_assets) > 0:
        print("\nâš ï¸ ê²½ê³ : ë‹¤ìŒ ì¢…ëª©ë“¤ì€ 'assets' í…Œì´ë¸”ì— IDê°€ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. DBì— ë¨¼ì € ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤.")
        for asset in missing_assets:
            print(f" - {asset}")
        print("ë°ì´í„° ì‚½ì…ì„ ê³„ì†í•˜ë ¤ë©´, ì´ ìì‚°ë“¤ì„ 'assets' í…Œì´ë¸”ì— ì¶”ê°€í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ìì‚° ì œê±° (í˜¹ì€ ì—ëŸ¬ ë°œìƒ)
        # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ ë§¤í•‘ëœ ë°ì´í„°ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
        df_final = df.dropna(subset=['asset_id', 'account_id']).copy()
        
    else:
        df_final = df.dropna(subset=['asset_id', 'account_id']).copy()

    # 6. ìµœì¢… ìŠ¤ëƒ…ìƒ· í…Œì´ë¸” êµ¬ì¡°ë¡œ ì •ë¦¬
    
    # â—ï¸ ì¤‘ìš”: ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ì„¤ì •
    # ì´ ë°ì´í„°ëŠ” í•œ ì‹œì ì˜ ì”ê³ ì´ë¯€ë¡œ, ë‚ ì§œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
    snapshot_date = datetime.now().strftime('%Y-%m-%d')
    df_final['snapshot_date'] = snapshot_date
    
    # ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ ë° ì´ë¦„ ì§€ì • (account_snapshots í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ê°€ì •)
    final_cols = {
        'account_id': 'account_id',
        'asset_id': 'asset_id',
        'snapshot_date': 'date', # DB ì»¬ëŸ¼ëª…ì€ 'date'ë¡œ ê°€ì •
        'quantity': 'quantity',
        'current_price': 'valuation_price',
        'avg_purchase_price': 'purchase_price',
        'valuation_amount': 'valuation_amount',
        'purchase_amount': 'purchase_amount',
    }
    
    df_snapshots = df_final[list(final_cols.keys())].rename(columns=final_cols)
    
    print(f"\nâœ… ìµœì¢… 'account_snapshots' ì¤€ë¹„ ë°ì´í„°: {len(df_snapshots)}ê±´")
    print(f"   ìŠ¤ëƒ…ìƒ· ë‚ ì§œ: {snapshot_date}")
    
    return df_snapshots

# --- 4. ì‹¤í–‰ ---

# ì´ì „ì— ì œê³µëœ CSV íŒŒì¼ì˜ ì „ì²´ ë‚´ìš©
file_content = """
The following table:
,,,,í•œêµ­ ê°œë³„,í•œêµ­ ETF,ë¯¸êµ­ ê°œë³„,êµ­ë‚´ìƒì¥ ë¯¸êµ­ETF,ì±„ê¶Œ,í˜„ê¸ˆ,êµ­ë‚´ì£¼ì‹,í•´ì™¸ì£¼ì‹,ë°°ë‹¹ì£¼,ê¸ˆ,ì±„ê¶Œ,ë‹¬ëŸ¬,í•©ê³„
... (ì¤‘ëµ) ...
""" # ì‹¤ì œë¡œëŠ” ì˜ ì „ì²´ ë‚´ìš©ì´ ë“¤ì–´ì™€ì•¼ í•¨

# ì‹¤ì œ íŒŒì¼ ë‚´ìš©ì„ ë³€ìˆ˜ì— í• ë‹¹ (ì œê³µëœ íŒŒì¼ì˜ `fullContent` ì „ì²´ë¥¼ ì‚¬ìš©)
csv_file_content = """
,,ì¦ê¶Œì‚¬,í‹°ì»¤(ì½”ë“œ),ì¢…ëª©ëª…,ì”ê³ ìˆ˜ëŸ‰,í˜„ì¬ê°€,í‰ê· ë§¤ì…ê°€,í‰ê°€ì†ìµ,ìˆ˜ìµë¥ ,í‰ê°€ ê¸ˆì•¡,ë§¤ì… ê¸ˆì•¡,ìˆ˜ìˆ˜ë£Œ,ì„¸ê¸ˆ,êµ¬ì„±,ë¹„ê³ 
,,ë¯¸ë˜ì—ì…‹ì—°ê¸ˆì €ì¶•,213630,PLUS ë¯¸êµ­ë‹¤ìš°ì¡´ìŠ¤ê³ ë°°ë‹¹ì£¼(í•©ì„± H),10,"18,535ì›","18,021ì›","4,669ì›",2.59%,"185,350ì›","180,210ì›",7ì›,463ì›,ë°°ë‹¹ì£¼,êµ­ë‚´ìƒì¥ ë¯¸êµ­ETF
... (ì¤‘ëµ: ìƒì„¸ ë°ì´í„° ëª©ë¡) ...
,,ë¯¸ë˜ì—ì…‹ì—°ê¸ˆì €ì¶•m(ì˜ˆ),,ë¯¸ë˜ì—ì…‹ì†”ë¡œëª¬ì¥ê¸°êµ­ê³µì±„,,,,,,"3,000,000ì›","3,000,000ì›",,,ì±„ê¶Œ,í˜„ê¸ˆ
,,,ì¢…ëª©ë²ˆí˜¸,ì¢…ëª©ëª… (êµ­ë¬¸),,,í‰ê· ë‹¨ê°€
... (í›„ëµ) ...
"""

# ìœ„ì˜ prepare_data_for_supabase í•¨ìˆ˜ì— `File Fetcher`ì—ì„œ ê°€ì ¸ì˜¨ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¸ìˆ˜ë¡œ ì „ë‹¬í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.
# ì˜ˆ: final_snapshots_df = prepare_data_for_supabase(csv_file_content)

# final_snapshots_dfë¥¼ Supabaseì— bulk insert í•©ë‹ˆë‹¤.
# ì˜ˆ: response = supabase.table('account_snapshots').insert(final_snapshots_df.to_dict('records')).execute()