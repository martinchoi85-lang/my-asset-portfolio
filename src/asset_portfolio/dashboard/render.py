import pandas as pd
import altair as alt
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import date, timedelta
from asset_portfolio.backend.infra.supabase_client import get_supabase_client
from asset_portfolio.backend.services.portfolio_weight_service import (
    load_asset_weight_timeseries,
    build_asset_weight_df,
    load_latest_asset_weights
)
from asset_portfolio.backend.services.portfolio_service import (
    get_portfolio_return_series,
    # load_asset_contribution_data, 
    calculate_asset_contributions
)
from asset_portfolio.backend.services.benchmark_service import (
    # load_cash_benchmark_series,
    # merge_portfolio_and_benchmark, 
    # merge_portfolio_and_benchmark_ffill,
    load_sp500_benchmark_series,
    align_portfolio_to_benchmark_calendar
)
from asset_portfolio.backend.services.manual_cost_basis_service import attach_manual_cost_basis
from asset_portfolio.backend.services.transaction_service import (
    TransactionService,
    CreateTransactionRequest,
)
from asset_portfolio.backend.infra import query
from asset_portfolio.dashboard.data import load_assets_lookup


@st.cache_data(ttl=600)
def load_asset_grouping_summary(user_id: str, account_id: str) -> pd.DataFrame:
    """
    ìì‚° ë¶„ë¥˜ ê¸°ì¤€(ìì‚° ìœ í˜•/ê¸°ì´ˆìì‚° í´ë˜ìŠ¤)ë³„ í‰ê°€ê¸ˆì•¡ í•©ê³„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    - ìºì‹œë¥¼ ì‚¬ìš©í•´ì„œ ë™ì¼í•œ ê³„ì¢Œ/ì‚¬ìš©ì ìš”ì²­ì„ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - Supabaseì—ì„œ ì›ë³¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³ , íŒŒì´ì¬ì—ì„œ ê·¸ë£¹ ì§‘ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    - asset_summary_liveê°€ ë¹„ì–´ ìˆìœ¼ë©´ daily_snapshotsì˜ ìµœì‹  ë‚ ì§œ ë°ì´í„°ë¥¼ ëŒ€ì²´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    supabase = get_supabase_client()

    # ê¸°ë³¸ ì¡°íšŒ: asset_summary_live + assets ì¡°ì¸
    query_builder = (
        supabase.table("asset_summary_live")
        .select(
            "asset_id, account_id, total_valuation_amount, "
            "assets (asset_type, underlying_asset_class)"
        )
    )

    # ê³„ì¢Œ ì„ íƒì´ "ì „ì²´"ì¸ì§€ ì—¬ë¶€ì— ë”°ë¼ í•„í„° ì¡°ê±´ì´ ë‹¬ë¼ì§
    if account_id and account_id != "__ALL__":
        query_builder = query_builder.eq("account_id", account_id)
    else:
        # ì „ì²´ ê³„ì¢Œ ì¡°íšŒ ì‹œ, ë¡œê·¸ì¸ ì‚¬ìš©ìì˜ ê³„ì¢Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ IN ì¡°ê±´ìœ¼ë¡œ ì¡°íšŒ
        user_accounts = query.get_accounts(user_id)
        user_account_ids = [acc["id"] for acc in user_accounts]
        if not user_account_ids:
            return pd.DataFrame(
                columns=["asset_type", "underlying_asset_class", "total_valuation_amount"]
            )
        query_builder = query_builder.in_("account_id", user_account_ids)

    rows = query_builder.execute().data or []

    # ============================================
    # 1) ìš°ì„  asset_summary_live ê¸°ë°˜ ë°ì´í„° ì •ê·œí™”
    # ============================================
    df = pd.json_normalize(rows, sep=".") if rows else pd.DataFrame()

    # ë°ì´í„° ì•ˆì „ì„±: ìˆ«ì ë³€í™˜ + ê²°ì¸¡ì¹˜ ê¸°ë³¸ê°’ ì²˜ë¦¬
    if not df.empty:
        df["total_valuation_amount"] = pd.to_numeric(
            df["total_valuation_amount"], errors="coerce"
        ).fillna(0)
        df["assets.asset_type"] = df["assets.asset_type"].fillna("ë¯¸ë¶„ë¥˜")
        df["assets.underlying_asset_class"] = df["assets.underlying_asset_class"].fillna("ë¯¸ë¶„ë¥˜")

        # í‘œì¤€í™”ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì •ë¦¬
        df = df.rename(
            columns={
                "assets.asset_type": "asset_type",
                "assets.underlying_asset_class": "underlying_asset_class",
            }
        )

        return df[["asset_type", "underlying_asset_class", "total_valuation_amount"]]

    # ==========================================================
    # 2) asset_summary_liveê°€ ë¹„ì–´ ìˆìœ¼ë©´ ìµœì‹  ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ëŒ€ì²´
    # ==========================================================
    latest_query = (
        supabase.table("daily_snapshots")
        .select("date")
        .order("date", desc=True)
        .limit(1)
    )
    if account_id and account_id != "__ALL__":
        latest_query = latest_query.eq("account_id", account_id)
    else:
        user_accounts = query.get_accounts(user_id)
        user_account_ids = [acc["id"] for acc in user_accounts]
        if not user_account_ids:
            return pd.DataFrame(
                columns=["asset_type", "underlying_asset_class", "total_valuation_amount"]
            )
        latest_query = latest_query.in_("account_id", user_account_ids)

    latest_row = latest_query.execute().data or []
    if not latest_row:
        return pd.DataFrame(
            columns=["asset_type", "underlying_asset_class", "total_valuation_amount"]
        )

    latest_date = latest_row[0]["date"]

    snapshot_query = (
        supabase.table("daily_snapshots")
        .select(
            "asset_id, account_id, valuation_amount, "
            "assets (asset_type, underlying_asset_class)"
        )
        .eq("date", latest_date)
    )
    if account_id and account_id != "__ALL__":
        snapshot_query = snapshot_query.eq("account_id", account_id)
    else:
        user_accounts = query.get_accounts(user_id)
        user_account_ids = [acc["id"] for acc in user_accounts]
        if not user_account_ids:
            return pd.DataFrame(
                columns=["asset_type", "underlying_asset_class", "total_valuation_amount"]
            )
        snapshot_query = snapshot_query.in_("account_id", user_account_ids)

    snapshot_rows = snapshot_query.execute().data or []
    if not snapshot_rows:
        return pd.DataFrame(
            columns=["asset_type", "underlying_asset_class", "total_valuation_amount"]
        )

    snapshot_df = pd.json_normalize(snapshot_rows, sep=".")
    snapshot_df["valuation_amount"] = pd.to_numeric(
        snapshot_df["valuation_amount"], errors="coerce"
    ).fillna(0)
    snapshot_df["assets.asset_type"] = snapshot_df["assets.asset_type"].fillna("ë¯¸ë¶„ë¥˜")
    snapshot_df["assets.underlying_asset_class"] = snapshot_df["assets.underlying_asset_class"].fillna("ë¯¸ë¶„ë¥˜")

    snapshot_df = snapshot_df.rename(
        columns={
            "assets.asset_type": "asset_type",
            "assets.underlying_asset_class": "underlying_asset_class",
            "valuation_amount": "total_valuation_amount",
        }
    )

    return snapshot_df[["asset_type", "underlying_asset_class", "total_valuation_amount"]]


def render_asset_grouping_pie_section(user_id: str, account_id: str):
    st.subheader("ğŸ§© ë™ì  ê·¸ë£¹í™” ì°¨íŠ¸")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    group_options = {
        "ìì‚° ìœ í˜• (asset_type)": "asset_type",
        "ê¸°ì´ˆìì‚° í´ë˜ìŠ¤ (underlying_asset_class)": "underlying_asset_class",
    }

    # ì‚¬ìš©ìê°€ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ë¬¶ì„ì§€ ì„ íƒí•˜ë„ë¡ ì œê³µ
    selected_label = st.selectbox(
        "ë¬¶ì„ ê¸°ì¤€ì„ ì„ íƒí•˜ì„¸ìš”.",
        list(group_options.keys()),
    )
    group_key = group_options[selected_label]

    # DBì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³ , ì„ íƒëœ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹ ì§‘ê³„
    raw_df = load_asset_grouping_summary(user_id=user_id, account_id=account_id)
    if raw_df.empty:
        st.info("í‘œì‹œí•  ìì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì„ íƒí•œ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€ê¸ˆì•¡ í•©ê³„ë¥¼ ê³„ì‚°
    grouped_df = (
        raw_df.groupby(group_key, as_index=False)["total_valuation_amount"]
        .sum()
        .sort_values("total_valuation_amount", ascending=False)
    )

    # ì‹œê°í™”ë¥¼ ìœ„í•œ íŒŒì´ ì°¨íŠ¸ (Plotly)
    fig = px.pie(
        grouped_df,
        names=group_key,
        values="total_valuation_amount",
        hole=0.35,
        title="ë¶„ë¥˜ ê¸°ì¤€ë³„ í‰ê°€ê¸ˆì•¡ ë¹„ì¤‘",
    )
    fig.update_traces(textposition="inside", textinfo="percent+label")
    fig.update_layout(height=360, margin=dict(t=40, l=10, r=10, b=10))

    st.plotly_chart(fig, width='stretch')

    # í‘œ í˜•íƒœë¡œë„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ë°ì´í„°í”„ë ˆì„ ì¶œë ¥
    st.dataframe(
        grouped_df.rename(
            columns={
                group_key: "ë¶„ë¥˜ ê¸°ì¤€",
                "total_valuation_amount": "í‰ê°€ê¸ˆì•¡ í•©ê³„",
            }
        ),
        width='stretch',
    )
    
    
def render_kpi_section(user_id: str, account_id: str, start_date: str, end_date: str):
    st.subheader("ğŸ“ˆ Portfolio ì „ì²´ ìˆ˜ìµë¥ ")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    # =========================
    # 1) í¬íŠ¸í´ë¦¬ì˜¤ ì‹œê³„ì—´
    # =========================
    portfolio_df = get_portfolio_return_series(user_id, account_id, start_date, end_date)

    if portfolio_df.empty:
        st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # =========================
    # 4) KPI ìš”ì•½ ì¹´ë“œ
    # =========================
    # portfolio_returnì´ NaNì¸ ê²½ìš°ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ, ë§ˆì§€ë§‰ ìœ íš¨ê°’ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
    pf_valid = portfolio_df.dropna(subset=["portfolio_return"]).copy()

    if not pf_valid.empty:
        last = pf_valid.sort_values("date").iloc[-1]
        total_val = float(last["valuation_amount"])
        total_buy = float(last["purchase_amount"])
        pnl = total_val - total_buy
        pnl_rate = (pnl / total_buy * 100) if total_buy > 0 else 0.0
        portfolio_return_pct = float(last["portfolio_return"]) * 100
    else:
        total_val = float(portfolio_df["valuation_amount"].dropna().iloc[-1]) if portfolio_df["valuation_amount"].notna().any() else 0.0
        total_buy = float(portfolio_df["purchase_amount"].dropna().iloc[-1]) if portfolio_df["purchase_amount"].notna().any() else 0.0
        pnl = total_val - total_buy
        pnl_rate = (pnl / total_buy * 100) if total_buy > 0 else 0.0
        portfolio_return_pct = 0.0

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("í‰ê°€ê¸ˆì•¡", f"{total_val:,.0f} ì›")
    c2.metric("íˆ¬ìì›ê¸ˆ", f"{total_buy:,.0f} ì›")
    c3.metric("í‰ê°€ì†ìµ", f"{pnl:,.0f} ì›", delta=f"{pnl_rate:.2f}%")
    c4.metric("ëˆ„ì  ìˆ˜ìµë¥ ", f"{portfolio_return_pct:.2f}%")


def render_benchmark_comparison_section(user_id: str, account_id: str, start_date: str, end_date: str):
    st.subheader("ë²¤ì¹˜ë§ˆí¬(S&P500)ì™€ ìˆ˜ìµë¥  ë¹„êµ")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        return

    # =========================
    # 1) í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ 
    # =========================
    portfolio_df = get_portfolio_return_series(user_id, account_id, start_date, end_date)

    if portfolio_df.empty:
        st.warning("ì¡°íšŒ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # =========================
    # 2) ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  (S&P 500)
    # =========================
    benchmark_start = start_date
    benchmark_end = end_date
    if benchmark_start is None or benchmark_end is None:
        portfolio_dates = pd.to_datetime(portfolio_df["date"], errors="coerce").dropna()
        if not portfolio_dates.empty:
            benchmark_start = portfolio_dates.min().date()
            benchmark_end = portfolio_dates.max().date()

    benchmark_df = pd.DataFrame()
    if benchmark_start is not None and benchmark_end is not None:
        benchmark_df = load_sp500_benchmark_series(
            start_date=benchmark_start,
            end_date=benchmark_end,
        )

    # =========================
    # 3) ë²¤ì¹˜ë§ˆí¬ ìº˜ë¦°ë”ì— ë§ì¶° forward-fill
    # =========================
    if not benchmark_df.empty:
        portfolio_df = align_portfolio_to_benchmark_calendar(portfolio_df, benchmark_df)
    else:
        st.warning("ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë„¤íŠ¸ì›Œí¬/API ì´ìŠˆ ê°€ëŠ¥)")

    # =========================
    # 4) ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
    # =========================
    chart_df = portfolio_df[["date", "portfolio_return"]].copy()
    chart_df["date"] = pd.to_datetime(chart_df["date"]).dt.date
    chart_df["portfolio_return_pct"] = chart_df["portfolio_return"] * 100

    if not benchmark_df.empty:
        b = benchmark_df.copy()
        b["date"] = pd.to_datetime(b["date"]).dt.date
        b["benchmark_return_pct"] = b["benchmark_return"] * 100
        chart_df = chart_df.merge(
            b[["date", "benchmark_return_pct"]],
            on="date",
            how="left",
        )

    # =========================
    # 5) ì´ì¤‘ Yì¶• ë¼ì¸ ì°¨íŠ¸ (ì¢Œ: í¬íŠ¸í´ë¦¬ì˜¤, ìš°: ë²¤ì¹˜ë§ˆí¬)
    # =========================
    fig = make_subplots(specs=[[{"secondary_y": True}]])

    fig.add_trace(
        go.Scatter(
            x=chart_df["date"],
            y=chart_df["portfolio_return_pct"],
            name="í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ (%)",
            mode="lines",
        ),
        secondary_y=False,
    )

    if "benchmark_return_pct" in chart_df.columns:
        fig.add_trace(
            go.Scatter(
                x=chart_df["date"],
                y=chart_df["benchmark_return_pct"],
                name="ë²¤ì¹˜ë§ˆí¬(S&P500) ìˆ˜ìµë¥ (%)",
                mode="lines",
            ),
            secondary_y=True,
        )

    fig.update_layout(
        height=350,
        margin=dict(t=10, l=10, r=10, b=10),
        legend=dict(orientation="h", yanchor="top", y=1.02, xanchor="left", x=0),
    )
    fig.update_yaxes(title_text="í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ (%)", secondary_y=False)
    fig.update_yaxes(title_text="ë²¤ì¹˜ë§ˆí¬(S&P500) ìˆ˜ìµë¥ (%)", secondary_y=True)

    st.plotly_chart(fig, width='stretch')
    st.caption(
        "â€» ìš°ë¦¬ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ (%)ì€ ì„ íƒí•œ ê¸°ê°„ì˜ í¬íŠ¸í´ë¦¬ì˜¤ ëˆ„ì  ìˆ˜ìµë¥ ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. "
        "(ê¸°ì¤€ì¼ ëŒ€ë¹„ ìì‚° ê°€ì¹˜ê°€ ì–´ëŠ ì •ë„ ì¦ê°€/ê°ì†Œí–ˆëŠ”ì§€ë¥¼ ë¹„ìœ¨ë¡œ í‘œì‹œ)"
    )


def render_asset_return_section(
    user_id: str,
    account_id: str,
    start_date: str,
    end_date: str,
):
    st.subheader("ğŸ“ˆ ìì‚°ë³„ ìˆ˜ìµë¥  ì¶”ì´")

    # ============================
    # 1. daily_snapshots + assets JOIN ì¡°íšŒ
    # ============================
    q = query.build_daily_snapshots_query(
        select_cols="""
            date,
            asset_id,
            valuation_amount,
            purchase_amount,
            assets (
                id,
                ticker,
                name_kr
            )
            """,
        start_date=start_date,
        end_date=end_date,
        user_id=user_id,
        account_id=account_id,
    )
    data = q.execute().data or []

    if not data:
        st.info("ìì‚°ë³„ ìˆ˜ìµë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ============================
    # 2. DataFrame ë³€í™˜ ë° ì •ê·œí™”
    # ============================
    df = pd.json_normalize(
        data,
        sep="."
    )

    # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ (ë°©ì–´ ì½”ë“œ)
    required_cols = {
        "date",
        "asset_id",
        "valuation_amount",
        "purchase_amount",
        "assets.ticker",
        "assets.name_kr",
    }

    missing = required_cols - set(df.columns)
    if missing:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
        return

    df["date"] = pd.to_datetime(df["date"])

    # ============================
    # 3. ìì‚° ì„ íƒ UI
    # ============================
    df["asset_label"] = (
        df["assets.ticker"] + " - " + df["assets.name_kr"]
    )

    asset_options = (
        df[["asset_id", "asset_label"]]
        .drop_duplicates()
        .sort_values("asset_label")
    )

    selected_asset_label = st.selectbox(
        "ìì‚° ì„ íƒ",
        asset_options["asset_label"].tolist()
    )

    selected_asset_id = asset_options[
        asset_options["asset_label"] == selected_asset_label
    ]["asset_id"].iloc[0]

    # ============================
    # 4. ì„ íƒ ìì‚° í•„í„°ë§
    # ============================
    asset_df = df[df["asset_id"] == selected_asset_id].copy()
    asset_df.sort_values("date", inplace=True)

    # ============================
    # 5. ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
    # (purchase_amount ê¸°ì¤€)
    # ============================

    asset_df = asset_df[
        (asset_df["valuation_amount"] > 0)
        & (asset_df["purchase_amount"] > 0)
    ]

    asset_df["return_rate"] = (
        asset_df["valuation_amount"] / asset_df["purchase_amount"] - 1
    )

    # ============================
    # 6. ì°¨íŠ¸ ì¶œë ¥
    # ============================
    asset_df["date"] = pd.to_datetime(asset_df["date"]).dt.date  # ì‹œê°„ ì œê±°
    st.line_chart(
        asset_df.set_index("date")["return_rate"],
        height=300,
        width='stretch'
    )

    # ============================
    # 7. í…Œì´ë¸” (í™•ì¸ìš©)
    # ============================
    with st.expander("ğŸ“„ ì›ë³¸ ë°ì´í„° í™•ì¸"):
        st.dataframe(
            asset_df[
                [
                    "date",
                    "valuation_amount",
                    "purchase_amount",
                    "return_rate",
                ]
            ]
        )





def render_latest_snapshot_table(user_id: str, account_id: str):
    st.subheader("ğŸ§¾ ìµœì‹  ìŠ¤ëƒ…ìƒ· í…Œì´ë¸”")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    supabase = get_supabase_client()

    latest_query = (
        supabase.table("daily_snapshots")
        .select("date")
        .order("date", desc=True)
        .limit(1)
    )
    if account_id != "__ALL__":
        latest_query = latest_query.eq("account_id", account_id)
    else:
        user_accounts = query.get_accounts(user_id)
        user_account_ids = [acc['id'] for acc in user_accounts]
        if not user_account_ids:
            st.info("daily_snapshots ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        latest_query = latest_query.in_("account_id", user_account_ids)


    latest_row = latest_query.execute().data or []

    if not latest_row:
        st.info("daily_snapshots ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    latest_date = latest_row[0]["date"]

    rows_query = (
        supabase.table("daily_snapshots")
        .select(
            "date, account_id, asset_id, quantity, purchase_price, valuation_price, "
            "valuation_amount, purchase_amount, currency, "
            "assets (name_kr, asset_type, price_source), accounts (name)"
        )
        .eq("date", latest_date)
    )
    if account_id != "__ALL__":
        rows_query = rows_query.eq("account_id", account_id)
    else:
        user_accounts = query.get_accounts(user_id)
        user_account_ids = [acc['id'] for acc in user_accounts]
        rows_query = rows_query.in_("account_id", user_account_ids)


    rows = rows_query.execute().data or []

    if not rows:
        st.info("ìµœì‹  ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    df = pd.json_normalize(rows, sep=".")

    df["quantity"] = pd.to_numeric(df["quantity"], errors="coerce")
    df = df[df["quantity"].fillna(0) != 0]
    if df.empty:
        st.info("ìµœì‹  ìŠ¤ëƒ…ìƒ·ì— ìˆ˜ëŸ‰ì´ 0ì¸ ìì‚°ë§Œ ìˆìŠµë‹ˆë‹¤.")
        return

    df = attach_manual_cost_basis(df, user_id=user_id)

    df["purchase_amount"] = pd.to_numeric(df["purchase_amount"], errors="coerce")
    df["valuation_amount"] = pd.to_numeric(df["valuation_amount"], errors="coerce")
    if "manual_principal" in df.columns:
        df["manual_principal"] = pd.to_numeric(df["manual_principal"], errors="coerce")

    df["profit_base_amount"] = df["purchase_amount"]
    manual_mask = df["assets.price_source"].fillna("").str.lower().str.strip().eq("manual")
    df.loc[manual_mask, "profit_base_amount"] = df.loc[manual_mask, "manual_principal"]

    df["profit_amount"] = df["valuation_amount"] - df["profit_base_amount"]
    df["profit_rate"] = df.apply(
        lambda r: (r["profit_amount"] / r["profit_base_amount"] * 100)
        if float(r["profit_base_amount"] or 0) > 0
        else 0.0,
        axis=1,
    )

    currency_map = {
        "krw": "ì›í™”",
        "usd": "ë‹¬ëŸ¬",
    }
    df["currency"] = df["currency"].apply(
        lambda x: currency_map.get(str(x).lower(), x) if x is not None else x
    )

    asset_type_map = {
        "cash": "ì˜ˆìˆ˜ê¸ˆ",
        "stock": "ì£¼ì‹",
        "deposit": "ì˜ˆì ê¸ˆ",
        "etf": "ETF",
        "fund": "í€ë“œë¥˜",
        "tdf": "TDF",
    }
    df["assets.asset_type"] = df["assets.asset_type"].apply(
        lambda x: asset_type_map.get(str(x).lower(), x) if x is not None else x
    )

    df = df.rename(
        columns={
            "accounts.name": "ê³„ì¢Œëª…",
            "assets.name_kr": "ìì‚°ëª…",
            "quantity": "ìˆ˜ëŸ‰",
            "purchase_price": "ë§¤ìˆ˜ë‹¨ê°€",
            "valuation_price": "í˜„ì¬ë‹¨ê°€",
            "manual_principal": "ì›ê¸ˆ(ìˆ˜ë™ìì‚°)",
            "valuation_amount": "í‰ê°€ê¸ˆì•¡",
            "profit_amount": "ìˆ˜ìµê¸ˆì•¡",
            "profit_rate": "ìˆ˜ìµë¥ ",
            "currency": "í†µí™”",
            "assets.asset_type": "ìì‚° íƒ€ì…",
        }
    )

    columns = [
        "ê³„ì¢Œëª…",
        "ìì‚°ëª…",
        "ìˆ˜ëŸ‰",
        "ë§¤ìˆ˜ë‹¨ê°€",
        "í˜„ì¬ë‹¨ê°€",
        "ì›ê¸ˆ(ìˆ˜ë™ìì‚°)",
        "í‰ê°€ê¸ˆì•¡",
        "ìˆ˜ìµê¸ˆì•¡",
        "ìˆ˜ìµë¥ ",
        "í†µí™”",
        "ìì‚° íƒ€ì…",
    ]

    st.caption(f"ê¸°ì¤€ì¼: {latest_date}")

    display_df = df[columns].copy()

    profit_amount_col = columns[7]
    profit_rate_col = columns[8]
    asset_name_col = columns[1]
    def _format_quantity(value):
        if pd.isna(value):
            return ""
        try:
            num = float(value)
        except (TypeError, ValueError):
            return value
        if num.is_integer():
            return f"{num:,.0f}"
        return f"{num:,.2f}"

    format_map = {
        columns[2]: _format_quantity,
        columns[3]: "{:,.2f}",
        columns[4]: "{:,.2f}",
        columns[5]: "{:,.0f}",
        columns[6]: "{:,.0f}",
        columns[7]: "{:,.0f}",
        profit_rate_col: "{:.2f}%",
    }

    for col in format_map:
        display_df[col] = pd.to_numeric(display_df[col], errors="coerce")

    profit_amount_idx = display_df.columns.get_loc(profit_amount_col)
    profit_rate_idx = display_df.columns.get_loc(profit_rate_col)
    asset_name_idx = display_df.columns.get_loc(asset_name_col)

    def _profit_color(row):
        rate = row[profit_rate_col]
        if pd.isna(rate):
            return [""] * len(row)
        if rate > 0:
            color = "color: red"
        elif rate < 0:
            color = "color: blue"
        else:
            color = ""
        styles = [""] * len(row)
        styles[asset_name_idx] = color
        styles[profit_amount_idx] = color
        styles[profit_rate_idx] = color
        return styles

    styled_df = display_df.style.format(format_map).apply(_profit_color, axis=1)

    st.dataframe(styled_df, width='stretch')


def render_account_selector(accounts: list):
    st.sidebar.subheader("ğŸ¦ ê³„ì¢Œ ì„ íƒ")

    if not accounts:
        st.sidebar.warning("ë“±ë¡ëœ ê³„ì¢Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ label â†’ account_id ë§¤í•‘
    options = {
        f"{a['brokerage']} | {a['name']}": a["id"]
        for a in accounts
    }

    # âœ… ì „ì²´ ê³„ì¢Œ ì˜µì…˜ ì¶”ê°€ (ë§¨ ìœ„)
    options = {"ì „ì²´ ê³„ì¢Œ (ALL)": "__ALL__", **options}

    # ê³„ì¢Œ ì„ íƒ UI
    selected_label = st.sidebar.selectbox(
        "ì¡°íšŒí•  ê³„ì¢Œë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(options.keys()),
        index=0,
        key="account_selector_label",
    )

    return options[selected_label]




def _get_min_snapshot_date(user_id: str, account_id: str):
    """
    daily_snapshotsì˜ ìµœì†Œ ë‚ ì§œë¥¼ ì¡°íšŒí•œë‹¤.
    - YTD ë³´ì •ì— ì‚¬ìš©
    """
    supabase = get_supabase_client()
    q = (
        supabase.table("daily_snapshots")
        .select("date")
        .order("date", desc=False)
        .limit(1)
    )
    if account_id and account_id != "__ALL__":
        q = q.eq("account_id", account_id)
    else:
        # 'ì „ì²´'ì¼ ê²½ìš° user_idì— ì†í•œ ëª¨ë“  ê³„ì¢Œë¥¼ ëŒ€ìƒìœ¼ë¡œ í•¨
        from asset_portfolio.backend.infra import query
        user_accounts = query.get_accounts(user_id)
        user_account_ids = [acc['id'] for acc in user_accounts]
        if not user_account_ids:
            return None
        q = q.in_("account_id", user_account_ids)


    rows = q.execute().data or []
    if not rows:
        return None

    return pd.to_datetime(rows[0]["date"], errors="coerce").date()

def resolve_date_range(user_id: str, period: str, account_id: str):
    """
    ê¸°ê°„ ì½”ë“œ("ì˜¤ëŠ˜", "ì¼ì£¼ì¼", "í•œë‹¬", "3ë‹¬(1ë¶„ê¸°)", "YTD(ì˜¬í•´)", "ALL")ë¥¼
    ì‹¤ì œ ì¡°íšŒìš© start_date, end_dateë¡œ ë³€í™˜
    """
    end_date = date.today()

    if period == "ì˜¤ëŠ˜":
        start_date = end_date
    elif period == "ì¼ì£¼ì¼":
        start_date = end_date - timedelta(days=7)
    elif period == "í•œë‹¬":
        start_date = end_date - timedelta(days=30)
    elif period == "3ë‹¬(1ë¶„ê¸°)":
        start_date = end_date - timedelta(days=90)
    elif period == "YTD(ì˜¬í•´)":
        start_date = date(end_date.year, 1, 1)
    elif period == "ALL":
        start_date = None
        end_date = None
    else:
        raise ValueError(f"Unknown period: {period}")
    
    # YTD êµ¬ê°„ì´ ë¹„ëŠ” ê²½ìš°, ì‹¤ì œ ë°ì´í„° ì‹œì‘ì¼ë¡œ ë³´ì •í•œë‹¤.
    note = None
    if period == "YTD(ì˜¬í•´)":
        min_date = _get_min_snapshot_date(user_id, account_id)
        if min_date and start_date and min_date > start_date:
            start_date = min_date
            note = f"YTD êµ¬ê°„ì— ë°ì´í„°ê°€ ì—†ì–´ ì‹œì‘ì¼ì„ {min_date}ë¡œ ë³´ì •í–ˆìŠµë‹ˆë‹¤."

    return start_date, end_date, note


def render_period_selector(user_id: str, account_id: str):
    st.sidebar.subheader("ğŸ“… ê¸°ê°„ ì„ íƒ")

    period = st.sidebar.radio(
        "ì¡°íšŒ ê¸°ê°„",
        options=["ì˜¤ëŠ˜", "ì¼ì£¼ì¼", "í•œë‹¬", "3ë‹¬(1ë¶„ê¸°)", "YTD(ì˜¬í•´)", "ALL"],
        index=1  # ê¸°ë³¸ê°’: "ì¼ì£¼ì¼"
    )

    start_date, end_date, note = resolve_date_range(user_id, period, account_id)
    if note:
        st.sidebar.caption(note)
    return start_date, end_date



def render_asset_weight_section(user_id: str, account_id: str, start_date: str, end_date: str):
    st.subheader("ğŸ“Š ìì‚° ë¹„ì¤‘ ë³€í™”")

    rows = load_asset_weight_timeseries(
        user_id=user_id,
        account_id=account_id,
        start_date=start_date,
        end_date=end_date,
    )
    
    df = build_asset_weight_df(rows)
    
    # ì´ì•¡ì´ 0ì¸ ë‚ ì§œëŠ” ì œê±°(ì˜ë¯¸ ì—†ëŠ” êµ¬ê°„ ì œê±°)
    # dfëŠ” build_asset_weight_df ê²°ê³¼(valuation_amount_krw, total_amount_krwê°€ ìˆìŒ)
    if "total_amount_krw" not in df.columns:
        st.warning("ìì‚° ë¹„ì¤‘ ë°ì´í„°ì— total_amount_krw ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df = df[df["total_amount_krw"] > 0].copy()
    if df.empty:
        st.info("ìì‚° ë¹„ì¤‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í‰ê°€ê¸ˆì•¡ í•©ê³„ê°€ 0ì¸ ë‚ ì§œë§Œ ì¡´ì¬)")
        return

    # =========================
    # âœ… ì•ˆì „ ê°€ë“œ: asset_idê°€ ì—†ìœ¼ë©´ pivot/ì§‘ê³„ ë¶ˆê°€
    # =========================
    if "asset_id" not in df.columns:
        st.error("build_asset_weight_df() ê²°ê³¼ì— asset_idê°€ ì—†ìŠµë‹ˆë‹¤. (pivot ì•ˆì •ì„±ì„ ìœ„í•´ í•„ìˆ˜)")
        with st.expander("ğŸ” ë””ë²„ê¹…: build_asset_weight_df() ê²°ê³¼ í™•ì¸"):
            st.write("columns =", list(df.columns))
            st.dataframe(df.head(50))
        return

    # =========================
    # âœ… ALL ëª¨ë“œ: (date, asset_id) ê¸°ì¤€ìœ¼ë¡œ ìœ ì¼í™” + weight ì¬ê³„ì‚°
    # =========================
    if account_id == "__ALL__":
        # valuation_amountê°€ ìˆì–´ì•¼ ì „ì²´ í‰ê°€ê¸ˆì•¡ í•©ì‚° ê°€ëŠ¥
        if "valuation_amount" not in df.columns:
            st.error("ALL ëª¨ë“œ í•©ì‚°ì„ ìœ„í•´ valuation_amount ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            with st.expander("ğŸ” ë””ë²„ê¹…: df í™•ì¸"):
                st.write("columns =", list(df.columns))
                st.dataframe(df.head(50))
            return

        df["valuation_amount"] = pd.to_numeric(df["valuation_amount"], errors="coerce").fillna(0.0)
        df["asset_id"] = pd.to_numeric(df["asset_id"], errors="coerce")
        df = df.dropna(subset=["asset_id"])
        df["asset_id"] = df["asset_id"].astype(int)

        # âœ… (date, asset_id)ë¡œ í•©ì‚°
        df_agg = (
            df.groupby(["date", "asset_id"], as_index=False)
              .agg(
                  valuation_amount=("valuation_amount", "sum"),
                  asset_name=("asset_name", "first"),
              )
        )

        # âœ… date_total ê³„ì‚°
        df_agg["date_total"] = df_agg.groupby("date")["valuation_amount"].transform("sum")

        # âœ… 0 division ë°©ì§€
        df_agg["weight"] = 0.0
        mask = df_agg["date_total"] > 0
        df_agg.loc[mask, "weight"] = df_agg.loc[mask, "valuation_amount"] / df_agg.loc[mask, "date_total"]

        df = df_agg[["date", "asset_id", "asset_name", "weight"]].copy()

    # =========================
    # âœ… pivotì€ asset_idë¡œ (name_kr ë³€ê²½/ì¤‘ë³µ ëŒ€ë¹„)
    # =========================    

    # ì–´ë–¤ ê²½ë¡œì—ì„œ ì˜¤ë“  weight ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ ì„ íƒ
    weight_col = None
    for c in ["weight", "weight_krw", "weight_pct", "weight_krw_pct"]:
        if c in df.columns:
            weight_col = c
            break

    if weight_col is None:
        st.error(f"ìì‚° ë¹„ì¤‘ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. df.columns={list(df.columns)}")
        return

    # df["date"] = pd.to_datetime(df["date"]).dt.date  # ì‹œê°„ ì œê±°
    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
    df = df.dropna(subset=["date"])

    pivot = (
        df.pivot_table(
            index="date",
            columns="asset_id",
            values=weight_col,
            aggfunc="sum",
        )
        .fillna(0)
        .sort_index()
    )

    # =========================
    # âœ… í‘œì‹œìš© ë¼ë²¨ ë§¤í•‘ (asset_id -> asset_name)
    # =========================
    id_to_label = (
        df[["asset_id", "asset_name"]]
        .drop_duplicates()
        .set_index("asset_id")["asset_name"]
        .to_dict()
    )

    pivot_display = pivot.rename(columns=lambda aid: id_to_label.get(aid, f"asset_id={aid}"))

    st.area_chart(pivot_display, height=350, width='stretch')

    with st.expander("ğŸ“„ ë””ë²„ê¹…: weight ì›ë³¸"):
        st.dataframe(df.sort_values(["date", weight_col], ascending=[True, False]).head(200))


def render_asset_contribution_section(
    user_id: str,
    account_id: str,
    start_date: str,
    end_date: str,
):
    st.subheader("ğŸ§© ìì‚°ë³„ ìˆ˜ìµë¥  ê¸°ì—¬ë„")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    snapshots = query.load_asset_contribution_data(
        user_id, account_id, start_date, end_date
    )

    df = calculate_asset_contributions(snapshots)

    if df.empty:
        st.warning("ê¸°ì—¬ë„ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìì‚°ëª… join
    assets = load_assets_lookup()
    df = df.merge(assets, on="asset_id", how="left")

    st.dataframe(
        df.sort_values("date", ascending=False),
        height=350,
        width='stretch'
    )

    st.caption("â€» ì „ì¼ í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€ë¹„ ê¸°ì—¬ë„ (%)")


def render_asset_contribution_stacked_area(
    user_id: str,
    account_id: str,
    start_date: str,
    end_date: str,
):
    st.subheader("ğŸ§© ìì‚°ë³„ ëˆ„ì  ê¸°ì—¬ë„ (Stacked Area)")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    snapshots = query.load_asset_contribution_data(user_id, account_id, start_date, end_date)
    df = calculate_asset_contributions(snapshots)

    if df.empty:
        st.warning("ê¸°ì—¬ë„ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìì‚°ëª… ì¡°ì¸
    assets = load_assets_lookup()
    df = df.merge(assets[["asset_id", "name_kr"]], on="asset_id", how="left")
    df["name_kr"] = df["name_kr"].fillna(df["asset_id"].astype(str))

    # =========================
    # ëˆ„ì  ê¸°ì—¬ë„ ê³„ì‚°
    # =========================
    df = df.sort_values(["asset_id", "date"])
    df["cum_contribution"] = df.groupby("asset_id")["contribution"].cumsum()
    df["cum_contribution_pct"] = df["cum_contribution"] * 100

    # ë„ˆë¬´ ë§ì€ ìì‚°ì´ë©´ ìƒìœ„ Nê°œë§Œ (UX ë³´í˜¸)
    top_n = st.slider("í‘œì‹œí•  ìì‚° ê°œìˆ˜(ìƒìœ„ ëˆ„ì  ê¸°ì—¬ë„ ê¸°ì¤€)", 5, 30, 12)

    latest_cum = (
        df.groupby(["asset_id", "name_kr"], as_index=False)["cum_contribution"]
        .last()
        .sort_values("cum_contribution", ascending=False)
    )
    top_assets = set(latest_cum.head(top_n)["asset_id"].tolist())
    df_plot = df[df["asset_id"].isin(top_assets)].copy()
    
    if df_plot.empty:
        st.warning("ëˆ„ì  ê¸°ì—¬ë„ ì°¨íŠ¸ì— í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í•„í„°ë§ ê²°ê³¼ empty)")
        return
    
    df_plot["date"] = pd.to_datetime(df_plot["date"])  # âœ… datetime ìœ ì§€
    
    # =========================
    # Altair stacked area
    # =========================
    chart = (
        alt.Chart(df_plot)
        .mark_area()
        .encode(
            # 2ë²ˆ ë°©ë²•: axis formatì„ ë‚ ì§œë§Œ ë‚˜ì˜¤ë„ë¡ ê°•ì œ
            x=alt.X("date:T", title="Date", axis=alt.Axis(format="%Y-%m-%d")),
            # ë¬¸ìì—´ ë‚ ì§œëŠ” O(Ordinal)ë¡œ ì²˜ë¦¬ â†’ ì‹œê°„(12 PM) í‘œì‹œê°€ ì‚¬ë¼ì§
            # ë‚ ì§œë¥¼ â€œì‹œê°„ ë°ì´í„°â€ê°€ ì•„ë‹ˆë¼ â€œë²”ì£¼(ordered)â€ë¡œ ì²˜ë¦¬(ë‹¨ì : ê¸°ê°„ì´ ê¸¸ë©´ í‹±ì´ ë„ˆë¬´ ë§ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
            # x=alt.X("date:O", title="Date"),
            # x=alt.X("date:T", title="Date"),
            y=alt.Y("cum_contribution_pct:Q", stack="zero", title="ëˆ„ì  ê¸°ì—¬ë„(%)"),
            color=alt.Color("name_kr:N", title="ìì‚°"),
            tooltip=[
                alt.Tooltip("date:T", title="Date"),
                alt.Tooltip("name_kr:N", title="ìì‚°"),
                alt.Tooltip("cum_contribution_pct:Q", title="ëˆ„ì ê¸°ì—¬ë„(%)", format=".2f"),
            ],
        )
        .properties(height=350)
    )

    st.altair_chart(chart, width='stretch')

    with st.expander("ğŸ“„ ëˆ„ì  ê¸°ì—¬ë„ ì›ë³¸"):
        st.dataframe(
            df_plot[["date", "asset_id", "name_kr", "contribution_pct", "cum_contribution_pct"]]
            .sort_values(["date", "cum_contribution_pct"], ascending=[True, False])
        )



def render_portfolio_treemap(
    user_id: str,
    account_id: str,
    start_date: str,
    end_date: str,
):
    st.subheader("ğŸ—ºï¸ Portfolio Treemap")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    mode = st.radio("Treemap ëª¨ë“œ", ["í˜„ì¬ ë¹„ì¤‘(í‰ê°€ê¸ˆì•¡)", "ê¸°ê°„ ëˆ„ì  ê¸°ì—¬ë„"], index=0, horizontal=True)

    # âœ… Plotly í‘œì‹œìš© í•œê¸€ ë¼ë²¨ (hover, legend ë“±ì— ë°˜ì˜)
    LABELS = {
        "valuation_amount": "í‰ê°€ê¸ˆì•¡",
        "name_kr": "ìì‚°ëª…",
        "asset_type": "ìì‚°ìœ í˜•",
        "market": "ì‹œì¥",
        "cum_pct": "ëˆ„ì  ê¸°ì—¬ë„(%)",
        "abs_cum": "ëˆ„ì  ê¸°ì—¬ë„(ì ˆëŒ€)",
    }

    assets = load_assets_lookup()

    if mode == "í˜„ì¬ ë¹„ì¤‘(í‰ê°€ê¸ˆì•¡)":
        # df_wëŠ” ìµœì†Œ ì»¬ëŸ¼: ['asset_id','valuation_amount','name_kr','asset_type','market'] ë¥¼ ê°€ì§€ë„ë¡ ì¤€ë¹„
        df_w = load_latest_asset_weights(user_id, account_id, start_date, end_date)
        if df_w.empty:
            st.warning("í•´ë‹¹ ê¸°ê°„ì— daily_snapshots ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        df_w = df_w.merge(assets[["asset_id", "name_kr", "asset_type", "market"]], on="asset_id", how="left")
        df_w["name_kr"] = df_w["name_kr"].fillna(df_w["asset_id"].astype(str))

        leaf_count = int(df_w["asset_id"].nunique())  # âœ… ë§ë‹¨ ê°œìˆ˜ ê·¼ì‚¬

        # âœ… ë§ë‹¨ì´ ì ìœ¼ë©´ ë” í¬ê²Œ, ë§ìœ¼ë©´ ëœ í¬ê²Œ(ìˆ«ìë¥¼ í•˜ë“œì½”ë”©í•˜ì§€ë§Œ "ë°ì´í„°ì— ë”°ë¼ ìë™ ë³€í™”" = adaptive)
        # - ìµœì†Œ/ìµœëŒ€ë§Œ ì •í•´ë‘ë©´ ì‚¬ìš©ì ì…ì¥ì—ì„œëŠ” "ìë™"ìœ¼ë¡œ ëŠê»´ì§‘ë‹ˆë‹¤.
        base = 22
        fontSizeByLeaf = max(12, min(base, int(28 - leaf_count * 0.6)))

        # âœ… KRW í™˜ì‚°ì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„ ì‚¬ìš©
        value_col = "valuation_amount_krw" if "valuation_amount_krw" in df_w.columns else "valuation_amount"

        if df_w.empty or df_w[value_col].sum() <= 0:
            st.warning("í‘œì‹œí•  í‰ê°€ê¸ˆì•¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìŠ¤ëƒ…ìƒ· ìƒì„±/ìˆ˜ë™ì…ë ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”)")
            return
        
        fig = px.treemap(
            df_w,
            path=["market", "asset_type", "name_kr"],
            values=value_col,
            # âœ… ìì‚°ìœ í˜•ë³„ë¡œ ìƒ‰ì„ ë‹¤ë¥´ê²Œ ì£¼ë©´ ì‹œê°ì ìœ¼ë¡œ í›¨ì”¬ êµ¬ë¶„ì´ ì˜ ë©ë‹ˆë‹¤.
            color="asset_type",
            # âœ… ì—¬ëŸ¬ ìƒ‰ì„ ì œê³µí•˜ëŠ” íŒ”ë ˆíŠ¸(ì›í•˜ëŠ” ê²ƒìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
            color_discrete_sequence=px.colors.qualitative.Alphabet,
            labels=LABELS,
            hover_data={
                "valuation_amount": ":,.0f",
                "market": True,
                "asset_type": True,
                "name_kr": True,
            }
        )
        fig.update_layout(height=550)
        fig.update_layout(margin=dict(t=20, l=10, r=10, b=10))
        fig.update_traces(
            hovertemplate="<b>%{label}</b><br>í‰ê°€ê¸ˆì•¡=%{value:,.0f}<extra></extra>"
        )
        fig.update_traces(textfont_size=fontSizeByLeaf)

        st.plotly_chart(fig, width='stretch')
        st.caption("â€» ë§ˆì§€ë§‰ ìŠ¤ëƒ…ìƒ· ë‚ ì§œ ê¸°ì¤€ í‰ê°€ê¸ˆì•¡ Treemap")        

        with st.expander("ğŸ“„ ë°ì´í„° ì›ë³¸"):
            st.dataframe(df_w.sort_values(["date"], ascending=[True]))

    else:
        # ê¸°ê°„ ëˆ„ì  ê¸°ì—¬ë„
        snapshots = query.load_asset_contribution_data(user_id, account_id, start_date, end_date)
        df_c = calculate_asset_contributions(snapshots)
        if df_c.empty:
            st.warning("ê¸°ì—¬ë„ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        df_c = df_c.sort_values(["asset_id", "date"])
        df_c["cum_contribution"] = df_c.groupby("asset_id")["contribution"].cumsum()

        latest = (
            df_c.groupby("asset_id", as_index=False)["cum_contribution"]
            .last()
        )

        latest = latest.merge(assets[["asset_id", "name_kr", "asset_type", "market"]], on="asset_id", how="left")
        latest["name_kr"] = latest["name_kr"].fillna(latest["asset_id"].astype(str))

        latest["abs_cum"] = latest["cum_contribution"].abs()
        latest["cum_pct"] = latest["cum_contribution"] * 100

        leaf_count = int(latest["asset_id"].nunique())
        base = 22
        fontSizeByLeaf = max(12, min(base, int(28 - leaf_count * 0.6)))


        fig = px.treemap(
            latest,
            path=["market", "asset_type", "name_kr"],
            values="abs_cum",
            color="cum_pct",
            color_continuous_scale=px.colors.diverging.RdYlGn,
            labels=LABELS,
        )
        fig.update_layout(height=550)
        fig.update_layout(margin=dict(t=20, l=10, r=10, b=10))
        fig.update_traces(
            hovertemplate="<b>%{label}</b><br>ëˆ„ì ê¸°ì—¬ë„=%{value:,.0f}<extra></extra>"
        )
        fig.update_traces(textfont_size=fontSizeByLeaf)
        st.plotly_chart(fig, width='stretch')
        st.caption("â€» ê¸°ê°„ ëˆ„ì  ê¸°ì—¬ë„ Treemap (ë©´ì =ì ˆëŒ€ê°’, ìƒ‰=ë°©í–¥/í¬ê¸°)")


def render_asset_contribution_section_full(
    user_id: str,
    account_id: str,
    start_date: str,
    end_date: str,
):
    st.subheader("ğŸ§© ìì‚°ë³„ ìˆ˜ìµë¥  ê¸°ì—¬ë„ ìš”ì•½")

    if not account_id:
        st.info("ê³„ì¢Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    # =========================
    # 1) ë°ì´í„° ë¡œë“œ + ê¸°ì—¬ë„ ê³„ì‚°
    # =========================
    snapshots = query.load_asset_contribution_data(user_id, account_id, start_date, end_date)
    df = calculate_asset_contributions(snapshots)

    if df.empty:
        st.warning("ê¸°ì—¬ë„ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    assets = load_assets_lookup()
    df = df.merge(
        assets[["asset_id", "name_kr", "asset_type", "market"]],
        on="asset_id",
        how="left",
    )
    df["name_kr"] = df["name_kr"].fillna(df["asset_id"].astype(str))

    # =========================
    # 2) ëˆ„ì  ê¸°ì—¬ë„ ê³„ì‚° (ìì‚°ë³„)
    # =========================
    df = df.sort_values(["asset_id", "date"])
    df["cum_contribution"] = df.groupby("asset_id")["contribution"].cumsum()
    df["cum_contribution_pct"] = df["cum_contribution"] * 100

    # ìµœì‹  ë‚ ì§œ ê¸°ì¤€ ëˆ„ì  ê¸°ì—¬ë„ ìŠ¤ëƒ…ìƒ·
    latest = (
        df.groupby(["asset_id", "name_kr", "asset_type", "market"], as_index=False)
        .last()[["asset_id", "name_kr", "asset_type", "market", "cum_contribution", "cum_contribution_pct"]]
        .sort_values("cum_contribution", ascending=False)
    )

    # =========================
    # 3) ìš”ì•½ ì¹´ë“œ (Top 3 / Bottom 3)
    # =========================
    st.markdown("#### ğŸ“Œ ì´ë²ˆ ê¸°ê°„ â€˜ì„±ê³¼ ë§Œë“  ìì‚°â€™ / â€˜ì„±ê³¼ ê¹Œë¨¹ì€ ìì‚°â€™")

    top_n = 3
    top = latest.head(top_n).copy()
    bottom = latest.tail(top_n).sort_values("cum_contribution").copy()

    colL, colR = st.columns(2)

    with colL:
        st.markdown("**ìƒìœ„ ê¸°ì—¬ Top 3**")
        if top.empty:
            st.info("Top ê¸°ì—¬ ìì‚°ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for i, (_, r) in enumerate(top.iterrows(), start=1):
                st.metric(
                    label=f"{i}. {r['name_kr']}",
                    value=f"{r['cum_contribution_pct']:.2f}%",
                )

    with colR:
        st.markdown("**í•˜ìœ„ ê¸°ì—¬ Bottom 3**")
        if bottom.empty:
            st.info("Bottom ê¸°ì—¬ ìì‚°ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for i, (_, r) in enumerate(bottom.iterrows(), start=1):
                st.metric(
                    label=f"{i}. {r['name_kr']}",
                    value=f"{r['cum_contribution_pct']:.2f}%",
                )

    st.caption("â€» ëˆ„ì  ê¸°ì—¬ë„ëŠ” â€˜ì „ì¼ í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€ê¸ˆì•¡ ëŒ€ë¹„ ì¼ê°„ ê¸°ì—¬ë„â€™ë¥¼ ëˆ„ì í•œ ê°’ì…ë‹ˆë‹¤.")

    st.divider()

    # =========================
    # 4) Stacked Area (ëˆ„ì  ê¸°ì—¬ë„)
    # =========================
    st.markdown("#### ğŸ“ˆ ìì‚°ë³„ ëˆ„ì  ê¸°ì—¬ë„ (Stacked Area)")

    max_assets = st.slider("í‘œì‹œí•  ìì‚° ê°œìˆ˜(ìƒìœ„ ëˆ„ì  ê¸°ì—¬ë„)", 5, 30, 12)

    top_assets = set(latest.head(max_assets)["asset_id"].tolist())
    df_plot = df[df["asset_id"].isin(top_assets)].copy()
    df_plot["date"] = pd.to_datetime(df_plot["date"])  # âœ… datetime ìœ ì§€

    chart = (
        alt.Chart(df_plot)
        .mark_area()
        .encode(
            x=alt.X("date:T", title="Date", axis=alt.Axis(format="%Y-%m-%d")),
            y=alt.Y("cum_contribution_pct:Q", stack="zero", title="ëˆ„ì  ê¸°ì—¬ë„(%)"),
            color=alt.Color("name_kr:N", title="ìì‚°"),
            tooltip=[
                alt.Tooltip("date:T", title="Date"),
                alt.Tooltip("name_kr:N", title="ìì‚°"),
                alt.Tooltip("cum_contribution_pct:Q", title="ëˆ„ì ê¸°ì—¬ë„(%)", format=".2f"),
            ],
        )
        .properties(height=400)
    )

    st.altair_chart(chart, width='stretch')

    # =========================
    # 5) ë””ë²„ê¹…/ê²€ì¦ìš© í…Œì´ë¸”
    # =========================
    with st.expander("ğŸ“„ ê¸°ì—¬ë„ ê³„ì‚° ê²°ê³¼(ìì‚°ë³„ ëˆ„ì ) í™•ì¸"):
        st.dataframe(
            latest.rename(columns={
                "cum_contribution_pct": "ëˆ„ì ê¸°ì—¬ë„(%)",
                "name_kr": "ìì‚°ëª…",
                "market": "ì‹œì¥",
                "asset_type": "ìœ í˜•",
            })[
                ["ìì‚°ëª…", "ì‹œì¥", "ìœ í˜•", "ëˆ„ì ê¸°ì—¬ë„(%)"]
            ],
            height=400,
            width='stretch'
        )


def render_transactions_table_section(user_id: str, account_id: str, start_date: str, end_date: str):
    st.subheader("ê±°ë˜ ë‚´ì—­")

    supabase = get_supabase_client()
    q = (
        supabase.table("transactions")
        .select("""
            id,
            account_id,
            asset_id,
            transaction_date,
            trade_type,
            quantity,
            price,
            fee,
            tax,
            memo,
            assets ( ticker, name_kr, currency ),
            accounts ( name, brokerage, old_owner, type )
        """)
        .order("transaction_date", desc=True)
    )

    if start_date is not None:
        q = q.gte("transaction_date", start_date)
    if end_date is not None:
        q = q.lte("transaction_date", end_date)

    if account_id and account_id != "__ALL__":
        q = q.eq("account_id", account_id)
    else:
        user_accounts = query.get_accounts(user_id)
        user_account_ids = [acc['id'] for acc in user_accounts]
        if not user_account_ids:
            st.info("ì„ íƒí•œ ê¸°ê°„ì— ê±°ë˜ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        q = q.in_("account_id", user_account_ids)

    response = q.execute()
    rows = response.data or []

    if not rows:
        st.info("ì„ íƒí•œ ê¸°ê°„ì— ê±°ë˜ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(rows)
    df_raw = df.copy()

    # ìˆ˜ì •/ì‚­ì œ UIìš© ë¼ë²¨ ê³„ì‚° (í‘œì‹œìš© ì»¬ëŸ¼ì€ ì›ë³¸ê³¼ ë¶„ë¦¬)
    if "accounts" not in df_raw.columns:
        df_raw["accounts"] = None
    if "assets" not in df_raw.columns:
        df_raw["assets"] = None

    trade_type_kr_map = {
        "BUY": "ë§¤ìˆ˜",
        "SELL": "ë§¤ë„",
        "DEPOSIT": "ì…ê¸ˆ",
        "WITHDRAW": "ì¶œê¸ˆ",
    }
    df_raw["transaction_date"] = pd.to_datetime(df_raw["transaction_date"]).dt.date
    df_raw["trade_type_kr"] = df_raw["trade_type"].map(trade_type_kr_map).fillna(df_raw["trade_type"])
    df_raw["asset_label"] = df_raw["assets"].apply(
        lambda x: f"{(x or {}).get('ticker', '')} | {(x or {}).get('name_kr', '')}".strip(" |")
    )
    df_raw["account_label"] = df_raw["accounts"].apply(
        lambda x: f"{(x or {}).get('brokerage', '')} | {(x or {}).get('name', '')} ({(x or {}).get('owner', '')})".strip(" |")
    )

    # accounts ì»¬ëŸ¼ì´ dict(JSON)ë¡œ ë‚´ë ¤ì˜¤ë©´ nameë§Œ ì¶”ì¶œí•´ í‘œì‹œ
    if "accounts" in df.columns:
        df["account_name"] = df["accounts"].apply(
            lambda x: (x or {}).get("name")
        )
        df = df.drop(columns=["accounts"], errors="ignore")

    # assets dictì—ì„œ í‘œì‹œìš© ì»¬ëŸ¼ ì¶”ì¶œ
    df["ticker"] = df["assets"].apply(lambda x: (x or {}).get("ticker"))
    df["asset_name"] = df["assets"].apply(lambda x: (x or {}).get("name_kr"))
    df["asset_currency"] = df["assets"].apply(lambda x: (x or {}).get("currency"))

    currency_map = {
        "krw": "ì›",
        "usd": "ë‹¬ëŸ¬",
    }
    df["asset_currency"] = df["asset_currency"].apply(
        lambda x: currency_map.get(str(x).lower(), x) if x is not None else x
    )

    # id/ë‚´ë¶€í‚¤/ì›ë³¸ dict ì»¬ëŸ¼ ìˆ¨ê¸°ê¸°
    df = df.drop(columns=["id", "account_id", "asset_id", "assets"], errors="ignore")

    # =========================
    # ì»¬ëŸ¼ëª… í‘œì‹œìš© ë§¤í•‘
    # =========================
    COL_KR = {
        "transaction_date": "ê±°ë˜ì¼",
        "trade_type": "ê±°ë˜êµ¬ë¶„",
        "ticker": "í‹°ì»¤",
        "asset_name": "ìì‚°ëª…",
        "asset_currency": "í†µí™”",
        "quantity": "ìˆ˜ëŸ‰/ê¸ˆì•¡",
        "price": "ê°€ê²©",
        "fee": "ìˆ˜ìˆ˜ë£Œ",
        "tax": "ì„¸ê¸ˆ",
        "memo": "ë©”ëª¨",
        "account_name": "ê³„ì¢Œ",
    }
    TRADE_TYPE_KR = {
        "BUY": "ë§¤ìˆ˜",
        "SELL": "ë§¤ë„",
        "DEPOSIT": "ì…ê¸ˆ",
        "WITHDRAW": "ì¶œê¸ˆ",
    }

    df["trade_type"] = df["trade_type"].map(TRADE_TYPE_KR).fillna(df["trade_type"])
    df["transaction_date"] = pd.to_datetime(df["transaction_date"]).dt.date

    df_display = df.rename(columns=COL_KR)

    display_order = [
        "ê±°ë˜ì¼", "ê±°ë˜êµ¬ë¶„", "í‹°ì»¤", "ìì‚°ëª…", "í†µí™”",
        "ìˆ˜ëŸ‰/ê¸ˆì•¡", "ê°€ê²©", "ìˆ˜ìˆ˜ë£Œ", "ì„¸ê¸ˆ", "ê³„ì¢Œ", "ë©”ëª¨"
    ]

    cols = [c for c in display_order if c in df_display.columns] + [c for c in df_display.columns if c not in display_order]
    df_display = df_display[cols]

    st.dataframe(df_display, width="stretch")

    with st.expander("âœï¸ ê±°ë˜ ìˆ˜ì •/ì‚­ì œ"):
        tx_rows = df_raw.sort_values("transaction_date", ascending=False).to_dict("records")
        if not tx_rows:
            st.info("ìˆ˜ì •/ì‚­ì œí•  ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        tx_label_map = {
            r["id"]: f"{r['transaction_date']} | {r['asset_label']} | {r['trade_type_kr']} | qty={r['quantity']} | price={r['price']} | id={r['id']}"
            for r in tx_rows
        }

        selected_tx_id = st.selectbox(
            "ìˆ˜ì •/ì‚­ì œí•  ê±°ë˜ ì„ íƒ",
            options=[r["id"] for r in tx_rows],
            format_func=lambda tid: tx_label_map.get(tid, str(tid)),
        )

        selected = next(r for r in tx_rows if r["id"] == selected_tx_id)

        st.caption(f"ê³„ì¢Œ: {selected.get('account_label', '')}")
        st.caption(f"ìì‚°: {selected.get('asset_label', '')}")

        trade_type_options = ["BUY", "SELL", "DEPOSIT", "WITHDRAW"]
        trade_type_labels = {
            "BUY": "ë§¤ìˆ˜",
            "SELL": "ë§¤ë„",
            "DEPOSIT": "ì…ê¸ˆ",
            "WITHDRAW": "ì¶œê¸ˆ",
        }
        trade_type = st.selectbox(
            "ê±°ë˜ êµ¬ë¶„",
            options=trade_type_options,
            index=trade_type_options.index(selected["trade_type"]),
            format_func=lambda v: trade_type_labels.get(v, v),
        )

        tx_date = st.date_input("ê±°ë˜ì¼", value=selected["transaction_date"])
        quantity = st.number_input("ìˆ˜ëŸ‰/ê¸ˆì•¡", min_value=0.0, value=float(selected["quantity"] or 0.0), step=1.0)

        if trade_type in {"DEPOSIT", "WITHDRAW"}:
            price = 1.0
            st.number_input("ê°€ê²©", min_value=0.0, value=1.0, step=1.0, disabled=True)
        else:
            price = st.number_input("ê°€ê²©", min_value=0.0, value=float(selected["price"] or 0.0), step=1.0)

        fee = st.number_input("ìˆ˜ìˆ˜ë£Œ", min_value=0.0, value=float(selected.get("fee") or 0.0), step=1.0)
        tax = st.number_input("ì„¸ê¸ˆ", min_value=0.0, value=float(selected.get("tax") or 0.0), step=1.0)
        memo = st.text_input("ë©”ëª¨", value=selected.get("memo") or "")

        auto_cash = st.checkbox("BUY/SELL ìë™ CASH ê±°ë˜ë„ í•¨ê»˜ ì¡°ì •", value=True)

        col_u, col_d = st.columns(2)
        with col_u:
            update_clicked = st.button("ê±°ë˜ ìˆ˜ì • ë°˜ì˜", type="primary")
        with col_d:
            delete_clicked = st.button("ê±°ë˜ ì‚­ì œ", type="secondary")

        if update_clicked:
            try:
                req = CreateTransactionRequest(
                    account_id=str(selected["account_id"]),
                    asset_id=int(selected["asset_id"]),
                    transaction_date=tx_date,
                    trade_type=str(trade_type),
                    quantity=float(quantity),
                    price=float(price),
                    fee=float(fee),
                    tax=float(tax),
                    memo=memo if memo else None,
                )
                with st.spinner("ê±°ë˜ ìˆ˜ì • ë° ìŠ¤ëƒ…ìƒ· ë¦¬ë¹Œë“œ ì¤‘..."):
                    result = TransactionService.update_transaction_and_rebuild(
                        int(selected_tx_id),
                        req,
                        auto_cash=auto_cash,
                    )
                st.success(
                    f"ìˆ˜ì • ì™„ë£Œ. (ë¦¬ë¹Œë“œ: {result['rebuilt_start_date']} ~ {result['rebuilt_end_date']})"
                )
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ìˆ˜ì • ì‹¤íŒ¨: {e}")

        if delete_clicked:
            try:
                with st.spinner("ê±°ë˜ ì‚­ì œ ë° ìŠ¤ëƒ…ìƒ· ë¦¬ë¹Œë“œ ì¤‘..."):
                    result = TransactionService.delete_transaction_and_rebuild(
                        int(selected_tx_id),
                        auto_cash=auto_cash,
                    )
                st.success(
                    f"ì‚­ì œ ì™„ë£Œ. (ë¦¬ë¹Œë“œ: {result['rebuilt_start_date']} ~ {result['rebuilt_end_date']})"
                )
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")


