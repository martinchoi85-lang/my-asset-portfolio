from __future__ import annotations

from dataclasses import dataclass
from datetime import date
import re
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

from asset_portfolio.backend.infra.supabase_client import get_supabase_client
from asset_portfolio.backend.services.asset_service import AssetService
from asset_portfolio.backend.services.transaction_service import (
    TransactionService,
    CreateTransactionRequest,
)
from asset_portfolio.dashboard.transaction_editor import _load_accounts_df, _load_assets_df


@dataclass
class PreparedTransaction:
    request: CreateTransactionRequest
    created_asset_payload: Optional[Dict[str, str]] = None


def _normalize_column_key(value: str) -> str:
    """ì»¬ëŸ¼ëª…ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ê³µë°±/íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ í†µì¼í•œë‹¤."""
    cleaned = re.sub(r"[^0-9a-zA-Zê°€-í£]", "", str(value)).lower()
    return cleaned


def _normalize_trade_type(value: str) -> Optional[str]:
    """ë§¤ìˆ˜/ë§¤ë„ í‘œê¸°ë¥¼ BUY/SELLë¡œ í‘œì¤€í™”í•œë‹¤."""
    if value is None:
        return None
    normalized = str(value).strip().lower()
    mapping = {
        "ë§¤ìˆ˜": "BUY",
        "buy": "BUY",
        "ë§¤ë„": "SELL",
        "sell": "SELL",
    }
    if normalized in mapping:
        return mapping[normalized]
    if normalized.upper() in {"BUY", "SELL"}:
        return normalized.upper()
    return None


def _normalize_currency(value: str) -> Optional[str]:
    """í†µí™” í‘œê¸°ë¥¼ KRW/USD ì¤‘ì‹¬ìœ¼ë¡œ í‘œì¤€í™”í•œë‹¤."""
    if value is None:
        return None
    normalized = str(value).strip().lower()
    mapping = {
        "krw": "KRW",
        "won": "KRW",
        "ì›": "KRW",
        "usd": "USD",
        "ë‹¬ëŸ¬": "USD",
        "us$": "USD",
        "$": "USD",
    }
    if normalized in mapping:
        return mapping[normalized]
    return normalized.upper()


def _normalize_market(value: str) -> Optional[str]:
    """ì‹œì¥ êµ¬ë¶„ì„ ë‚´ë¶€ í‘œì¤€ê°’ìœ¼ë¡œ ë§ì¶˜ë‹¤."""
    if value is None:
        return None
    normalized = str(value).strip().lower()
    mapping = {
        "kospi": "korea",
        "ì½”ìŠ¤í”¼": "korea",
        "kosdaq": "korea",
        "ì½”ìŠ¤ë‹¥": "korea",
        "krx": "korea",
        "korea": "korea",
        "nyse": "usa",
        "nasdaq": "usa",
        "usa": "usa",
        "us": "usa",
        "america": "usa",
    }
    return mapping.get(normalized, normalized)


def _map_columns(df: pd.DataFrame, aliases: Dict[str, List[str]]) -> Tuple[pd.DataFrame, List[str]]:
    """ì—…ë¡œë“œëœ ì»¬ëŸ¼ì„ í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘í•œë‹¤."""
    normalized_columns = { _normalize_column_key(col): col for col in df.columns }
    rename_map: Dict[str, str] = {}
    missing_fields: List[str] = []

    for canonical, candidates in aliases.items():
        found = None
        for candidate in candidates:
            key = _normalize_column_key(candidate)
            if key in normalized_columns:
                found = normalized_columns[key]
                break
        if found:
            rename_map[found] = canonical
        else:
            missing_fields.append(canonical)

    return df.rename(columns=rename_map), missing_fields


def _get_account_id_by_name(accounts_df: pd.DataFrame, account_name: str) -> Tuple[Optional[str], Optional[str]]:
    """ê³„ì¢Œëª…ì„ account_idë¡œ ë§¤ì¹­í•˜ê³ , ë¬¸ì œ ë°œìƒ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ëŒë ¤ì¤€ë‹¤."""
    matched = accounts_df[accounts_df["name"] == account_name]
    if matched.empty:
        return None, f"ê³„ì¢Œëª… '{account_name}' ì´(ê°€) ë“±ë¡ëœ ê³„ì¢Œì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    if len(matched) > 1:
        return None, f"ê³„ì¢Œëª… '{account_name}' ì´(ê°€) ì¤‘ë³µë˜ì–´ ê³„ì¢Œë¥¼ í™•ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return str(matched.iloc[0]["id"]), None


def _get_asset_row_by_ticker(assets_df: pd.DataFrame, ticker: str) -> Optional[pd.Series]:
    matched = assets_df[assets_df["ticker"].fillna("").str.upper() == ticker]
    if matched.empty:
        return None
    return matched.iloc[0]


def _find_existing_duplicate(
    *,
    account_id: str,
    asset_id: int,
    transaction_date: date,
    trade_type: str,
    quantity: float,
    price: float,
    tax: float,
) -> bool:
    """ê¸°ì¡´ transactions í…Œì´ë¸”ì— ê°™ì€ ê±°ë˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•œë‹¤."""
    supabase = get_supabase_client()
    resp = (
        supabase.table("transactions")
        .select("id")
        .eq("account_id", account_id)
        .eq("asset_id", asset_id)
        .eq("transaction_date", transaction_date.isoformat())
        .eq("trade_type", trade_type)
        .eq("quantity", quantity)
        .eq("price", price)
        # .eq("tax", tax)   // ì„¸ê¸ˆì€ í•„í„°ë§ ì¡°ê±´ì—ì„œ ì œì™¸
        .limit(1)
        .execute()
    )
    return bool(resp.data)


def _render_required_fields_table(field_rows: List[Dict[str, str]]) -> None:
    st.markdown("#### âœ… ì—…ë¡œë“œ í•„ìˆ˜ í•„ë“œ & ì˜ˆì‹œ")
    st.dataframe(pd.DataFrame(field_rows))


def _render_account_reference_table(user_id: str) -> None:
    accounts_df = _load_accounts_df(user_id)
    if accounts_df.empty:
        st.warning("ë“±ë¡ëœ ê³„ì¢Œê°€ ì—†ìŠµë‹ˆë‹¤. ê³„ì¢Œë¥¼ ë¨¼ì € ë“±ë¡í•˜ì„¸ìš”.")
        return
    st.markdown("#### âœ… í˜„ì¬ ë“±ë¡ëœ ê³„ì¢Œ ëª©ë¡")
    display_df = accounts_df[["brokerage", "name", "type", "old_owner"]].copy()
    display_df.rename(
        columns={
            "brokerage": "ì¦ê¶Œì‚¬",
            "name": "ê³„ì¢Œëª…",
            "type": "ê³„ì¢Œìœ í˜•",
            "owner": "ì†Œìœ ì",
        },
        inplace=True,
    )
    st.dataframe(display_df, width='stretch')


def _get_latest_transaction_dates(user_id: str) -> pd.DataFrame:
    """ê³„ì¢Œë³„ ìµœê·¼ ê±°ë˜ì¼ì„ ì¡°íšŒí•´ ì¤‘ë³µ ì…ë ¥ì„ ì˜ˆë°©í•˜ë„ë¡ ë•ëŠ”ë‹¤."""
    accounts_df = _load_accounts_df(user_id)
    if accounts_df.empty:
        return pd.DataFrame()

    supabase = get_supabase_client()
    latest_rows = []
    for _, row in accounts_df.iterrows():
        account_id = str(row["id"])
        resp = (
            supabase.table("transactions")
            .select("transaction_date")
            .eq("account_id", account_id)
            .order("transaction_date", desc=True)
            .limit(1)
            .execute()
        )
        tx_date = None
        if resp.data:
            tx_date = resp.data[0]["transaction_date"]
        latest_rows.append({
            "ì¦ê¶Œì‚¬": row["brokerage"],
            "ê³„ì¢Œëª…": row["name"],
            "ìµœê·¼ ê±°ë˜ì¼": tx_date or "-",
        })
    return pd.DataFrame(latest_rows)


def _read_uploaded_file(uploaded_file) -> Optional[pd.DataFrame]:
    if uploaded_file is None:
        return None
    file_name = uploaded_file.name.lower()
    if file_name.endswith(".csv"):
        return pd.read_csv(uploaded_file)
    if file_name.endswith(".xlsx") or file_name.endswith(".xls"):
        return pd.read_excel(uploaded_file)
    st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” XLSXë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    return None


def _prepare_trade_rows(df: pd.DataFrame, user_id: str) -> Tuple[List[PreparedTransaction], List[str]]:
    errors: List[str] = []
    prepared: List[PreparedTransaction] = []
    accounts_df = _load_accounts_df(user_id)
    assets_df = _load_assets_df()

    seen_keys = set()

    for idx, row in df.iterrows():
        row_number = idx + 2  # CSV í—¤ë” í¬í•¨ì„ ê³ ë ¤í•œ í–‰ ë²ˆí˜¸ í‘œì‹œ
        account_name = str(row.get("account_name") or "").strip()
        if not account_name:
            errors.append(f"{row_number}í–‰: ê³„ì¢Œëª…ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            continue

        account_id, account_error = _get_account_id_by_name(accounts_df, account_name)
        if account_error:
            errors.append(f"{row_number}í–‰: {account_error}")
            continue

        ticker = str(row.get("ticker") or "").strip().upper()
        if not ticker:
            errors.append(f"{row_number}í–‰: í‹°ì»¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            continue

        trade_type = _normalize_trade_type(row.get("trade_type"))
        if not trade_type:
            errors.append(f"{row_number}í–‰: ê±°ë˜ íƒ€ì…ì´ ë§¤ìˆ˜/ë§¤ë„/BUY/SELL ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
            continue

        quantity = pd.to_numeric(row.get("quantity"), errors="coerce")
        price = pd.to_numeric(row.get("price"), errors="coerce")
        fee = pd.to_numeric(row.get("fee"), errors="coerce")
        tax = pd.to_numeric(row.get("tax"), errors="coerce")

        if pd.isna(quantity) or quantity <= 0:
            errors.append(f"{row_number}í–‰: ìˆ˜ëŸ‰(quantity)ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
            continue
        if pd.isna(price) or price <= 0:
            errors.append(f"{row_number}í–‰: ë‹¨ê°€(price)ëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
            continue

        tx_date = pd.to_datetime(row.get("transaction_date"), errors="coerce")
        if pd.isna(tx_date):
            errors.append(f"{row_number}í–‰: ê±°ë˜ì¼(transaction_date)ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        normalized_currency = _normalize_currency(row.get("currency"))
        normalized_market = _normalize_market(row.get("market"))
        asset_row = _get_asset_row_by_ticker(assets_df, ticker)
        created_asset_payload: Optional[Dict[str, str]] = None

        if asset_row is None:
            asset_name = str(row.get("asset_name") or "").strip()
            asset_type = str(row.get("asset_type") or "").strip() or "stock"

            if not asset_name:
                errors.append(f"{row_number}í–‰: ì‹ ê·œ ìì‚° ìƒì„±ì— í•„ìš”í•œ ì¢…ëª©ëª…(asset_name)ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
            if not normalized_currency:
                errors.append(f"{row_number}í–‰: ì‹ ê·œ ìì‚° ìƒì„±ì— í•„ìš”í•œ í†µí™”(currency)ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            created_asset_payload = {
                "ticker": ticker,
                "name_kr": asset_name,
                "asset_type": asset_type,
                "currency": normalized_currency,
                "market": normalized_market,
            }
        else:
            if normalized_currency:
                existing_currency = _normalize_currency(asset_row.get("currency"))
                if existing_currency and existing_currency != normalized_currency:
                    errors.append(
                        f"{row_number}í–‰: ì—…ë¡œë“œ í†µí™”({normalized_currency})ê°€ ê¸°ì¡´ ìì‚° í†µí™”({existing_currency})ì™€ ë‹¤ë¦…ë‹ˆë‹¤."
                    )
                    continue

        fee_value = float(fee) if not pd.isna(fee) else 0.0
        tax_value = float(tax) if not pd.isna(tax) else 0.0
        memo = str(row.get("memo") or "").strip() or None

        # âœ… íŒŒì¼ ë‚´ë¶€ ì¤‘ë³µ ì²´í¬
        dedupe_key = (account_id, ticker, tx_date.date().isoformat(), trade_type, float(quantity), float(price))
        if dedupe_key in seen_keys:
            errors.append(f"{row_number}í–‰: ì—…ë¡œë“œ íŒŒì¼ ë‚´ ì¤‘ë³µ ê±°ë˜ê°€ ìˆìŠµë‹ˆë‹¤.")
            continue
        seen_keys.add(dedupe_key)

        # âœ… ê¸°ì¡´ DB ì¤‘ë³µ ì²´í¬ (ìì‚°ì´ ì´ë¯¸ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        if asset_row is not None:
            if _find_existing_duplicate(
                account_id=account_id,
                asset_id=int(asset_row["id"]),
                transaction_date=tx_date.date(),
                trade_type=trade_type,
                quantity=float(quantity),
                price=float(price),
                tax=tax_value,
            ):
                errors.append(f"{row_number}í–‰: ë™ì¼í•œ ê±°ë˜ê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                continue

        prepared.append(
            PreparedTransaction(
                request=CreateTransactionRequest(
                    account_id=account_id,
                    asset_id=int(asset_row["id"]) if asset_row is not None else -1,
                    transaction_date=tx_date.date(),
                    trade_type=trade_type,
                    quantity=float(quantity),
                    price=float(price),
                    fee=fee_value,
                    tax=tax_value,
                    memo=memo,
                ),
                created_asset_payload=created_asset_payload,
            )
        )

    return prepared, errors


def _prepare_dividend_rows(df: pd.DataFrame, user_id: str) -> Tuple[List[PreparedTransaction], List[str]]:
    errors: List[str] = []
    prepared: List[PreparedTransaction] = []
    accounts_df = _load_accounts_df(user_id)

    seen_keys = set()

    for idx, row in df.iterrows():
        row_number = idx + 2
        account_name = str(row.get("account_name") or "").strip()
        if not account_name:
            errors.append(f"{row_number}í–‰: ê³„ì¢Œëª…ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            continue

        account_id, account_error = _get_account_id_by_name(accounts_df, account_name)
        if account_error:
            errors.append(f"{row_number}í–‰: {account_error}")
            continue

        ticker = str(row.get("ticker") or "").strip().upper()
        asset_name = str(row.get("asset_name") or "").strip()
        market = _normalize_market(row.get("market"))
        currency = _normalize_currency(row.get("currency"))

        if not ticker or not asset_name:
            errors.append(f"{row_number}í–‰: í‹°ì»¤ ë˜ëŠ” ì¢…ëª©ëª…ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            continue
        if not currency:
            errors.append(f"{row_number}í–‰: í†µí™”(currency)ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            continue

        gross = pd.to_numeric(row.get("dividend_gross"), errors="coerce")
        net = pd.to_numeric(row.get("dividend_net"), errors="coerce")
        if pd.isna(gross) or pd.isna(net):
            errors.append(f"{row_number}í–‰: ë°°ë‹¹ê¸ˆ(ì„¸ì „/ì„¸í›„) ê°’ì„ ìˆ«ìë¡œ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
        if gross < net:
            errors.append(f"{row_number}í–‰: ë°°ë‹¹ê¸ˆ(ì„¸ì „)ì´ ì„¸í›„ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.")
            continue

        payout_date = pd.to_datetime(row.get("transaction_date"), errors="coerce")
        if pd.isna(payout_date):
            errors.append(f"{row_number}í–‰: ì§€ê¸‰ì¼ì(transaction_date)ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        try:
            cash_asset_id = TransactionService._get_cash_asset_id_by_currency(currency)
        except Exception as exc:
            errors.append(f"{row_number}í–‰: {exc}")
            continue

        tax_value = float(gross - net)
        memo = f"ë°°ë‹¹ê¸ˆ | {ticker} | {asset_name}"
        if market:
            memo += f" | {market}"

        dedupe_key = (account_id, cash_asset_id, payout_date.date().isoformat(), float(net), tax_value)
        if dedupe_key in seen_keys:
            errors.append(f"{row_number}í–‰: ì—…ë¡œë“œ íŒŒì¼ ë‚´ ì¤‘ë³µ ë°°ë‹¹ê¸ˆì´ ìˆìŠµë‹ˆë‹¤.")
            continue
        seen_keys.add(dedupe_key)

        if _find_existing_duplicate(
            account_id=account_id,
            asset_id=cash_asset_id,
            transaction_date=payout_date.date(),
            trade_type="DEPOSIT",
            quantity=float(net),
            price=1.0,
            tax=tax_value,
        ):
            errors.append(f"{row_number}í–‰: ë™ì¼í•œ ë°°ë‹¹ê¸ˆ ì…ê¸ˆ ê±°ë˜ê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            continue

        prepared.append(
            PreparedTransaction(
                request=CreateTransactionRequest(
                    account_id=account_id,
                    asset_id=cash_asset_id,
                    transaction_date=payout_date.date(),
                    trade_type="DEPOSIT",
                    quantity=float(net),
                    price=1.0,
                    fee=0.0,
                    tax=tax_value,
                    memo=memo,
                )
            )
        )

    return prepared, errors


def _execute_upload(prepared_rows: List[PreparedTransaction], auto_cash: bool) -> Tuple[int, List[str]]:
    """ê²€ì¦ì´ ëë‚œ ê±°ë˜ë¥¼ ì‹¤ì œë¡œ insertí•œë‹¤."""
    created_assets: List[str] = []
    success_count = 0

    for prepared in prepared_rows:
        req = prepared.request

        if prepared.created_asset_payload:
            # âœ… ì‹ ê·œ ìì‚°ì„ ë¨¼ì € ìƒì„±í•˜ê³  asset_idë¥¼ ê°±ì‹ í•œë‹¤.
            created = AssetService.create_asset_minimal(**prepared.created_asset_payload)
            req = CreateTransactionRequest(
                account_id=req.account_id,
                asset_id=int(created["id"]),
                transaction_date=req.transaction_date,
                trade_type=req.trade_type,
                quantity=req.quantity,
                price=req.price,
                fee=req.fee,
                tax=req.tax,
                memo=req.memo,
            )
            created_assets.append(created["ticker"])

        TransactionService.create_transaction_and_rebuild(req, auto_cash=auto_cash)
        success_count += 1

    return success_count, created_assets


def render_transaction_importer(user_id: str) -> None:
    st.title("ğŸ“¥ Transaction Importer")
    st.caption("CSV/XLSX ì—…ë¡œë“œë¡œ ë§¤ë§¤ ë‚´ì—­ ë˜ëŠ” ë°°ë‹¹ê¸ˆ ë‚´ì—­ì„ ì¼ê´„ ë“±ë¡í•©ë‹ˆë‹¤.")

    import_type = st.radio(
        "ì—…ë¡œë“œ ìœ í˜• ì„ íƒ",
        ["ë§¤ë§¤ ë‚´ì—­", "ë°°ë‹¹ê¸ˆ ë‚´ì—­"],
        horizontal=True,
    )

    with st.expander("ğŸ“Œ í•„ìˆ˜ í•„ë“œ & ì˜ˆì‹œ ë³´ê¸°", expanded=True):
        if import_type == "ë§¤ë§¤ ë‚´ì—­":
            _render_required_fields_table([
                {"í•„ë“œ": "ê³„ì¢Œëª…", "ì˜ˆì‹œ": "í‚¤ì›€ì¦ê¶Œ_í™ê¸¸ë™_ìœ„íƒ"},
                {"í•„ë“œ": "ê±°ë˜ì¼", "ì˜ˆì‹œ": "2024-12-31"},
                {"í•„ë“œ": "í‹°ì»¤", "ì˜ˆì‹œ": "AAPL / 005930"},
                {"í•„ë“œ": "ê±°ë˜íƒ€ì…", "ì˜ˆì‹œ": "ë§¤ìˆ˜ / ë§¤ë„ / BUY / SELL"},
                {"í•„ë“œ": "ìˆ˜ëŸ‰", "ì˜ˆì‹œ": "10"},
                {"í•„ë“œ": "ë‹¨ê°€", "ì˜ˆì‹œ": "150.5"},
                {"í•„ë“œ": "(ì„ íƒ) ìˆ˜ìˆ˜ë£Œ", "ì˜ˆì‹œ": "1.25"},
                {"í•„ë“œ": "(ì„ íƒ) ì„¸ê¸ˆ", "ì˜ˆì‹œ": "0.75"},
                {"í•„ë“œ": "(ì„ íƒ) ë©”ëª¨", "ì˜ˆì‹œ": "í•´ì™¸ì£¼ì‹ ë§¤ìˆ˜"},
                {"í•„ë“œ": "(ì„ íƒ) ì¢…ëª©ëª…", "ì˜ˆì‹œ": "Apple Inc"},
                {"í•„ë“œ": "(ì„ íƒ) í†µí™”", "ì˜ˆì‹œ": "USD / KRW"},
                {"í•„ë“œ": "(ì„ íƒ) ì‹œì¥", "ì˜ˆì‹œ": "korea / usa"},
                {"í•„ë“œ": "(ì„ íƒ) ìì‚°ìœ í˜•", "ì˜ˆì‹œ": "stock"},
            ])
        else:
            _render_required_fields_table([
                {"í•„ë“œ": "ê³„ì¢Œëª…", "ì˜ˆì‹œ": "í‚¤ì›€ì¦ê¶Œ_í™ê¸¸ë™_ìœ„íƒ"},
                {"í•„ë“œ": "ì§€ê¸‰ì¼ì", "ì˜ˆì‹œ": "2024-12-31"},
                {"í•„ë“œ": "í‹°ì»¤", "ì˜ˆì‹œ": "AAPL / 005930"},
                {"í•„ë“œ": "ì‹œì¥êµ¬ë¶„", "ì˜ˆì‹œ": "korea / usa"},
                {"í•„ë“œ": "í†µí™”", "ì˜ˆì‹œ": "USD / KRW"},
                {"í•„ë“œ": "ë°°ë‹¹ê¸ˆ(ì„¸í›„)", "ì˜ˆì‹œ": "85.5"},
                {"í•„ë“œ": "ë°°ë‹¹ê¸ˆ(ì„¸ì „)", "ì˜ˆì‹œ": "100.0"},
                {"í•„ë“œ": "(ì„ íƒ) ì¢…ëª©ëª…", "ì˜ˆì‹œ": "Apple Inc"},
            ])

    with st.expander("ğŸ“Œ ë“±ë¡ëœ ê³„ì¢Œ í™•ì¸", expanded=False):
        _render_account_reference_table(user_id)

    with st.expander("ğŸ“Œ ê³„ì¢Œë³„ ìµœê·¼ ê±°ë˜ì¼", expanded=False):
        latest_df = _get_latest_transaction_dates(user_id)
        if latest_df.empty:
            st.info("ìµœê·¼ ê±°ë˜ì¼ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(latest_df, width='stretch')

    uploaded_file = st.file_uploader("CSV ë˜ëŠ” XLSX íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"])
    if not uploaded_file:
        return

    raw_df = _read_uploaded_file(uploaded_file)
    if raw_df is None or raw_df.empty:
        st.error("ì—…ë¡œë“œí•œ íŒŒì¼ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if import_type == "ë§¤ë§¤ ë‚´ì—­":
        aliases = {
            "account_name": ["ê³„ì¢Œëª…", "account", "account_name"],
            "transaction_date": ["ê±°ë˜ì¼", "ì²´ê²°ì¼", "ë§¤ë§¤ì¼ì", "transaction_date"],
            "ticker": ["í‹°ì»¤", "ì¢…ëª©ì½”ë“œ", "ticker"],
            "trade_type": ["ê±°ë˜íƒ€ì…", "ë§¤ìˆ˜/ë§¤ë„", "êµ¬ë¶„", "trade_type"],
            "quantity": ["ìˆ˜ëŸ‰", "ê±°ë˜ìˆ˜ëŸ‰", "quantity"],
            "price": ["ë‹¨ê°€", "ì²´ê²°ê°€", "price"],
            "fee": ["ìˆ˜ìˆ˜ë£Œ", "fee"],
            "tax": ["ì„¸ê¸ˆ", "tax"],
            "memo": ["ë©”ëª¨", "memo"],
            "asset_name": ["ì¢…ëª©ëª…", "ìì‚°ëª…", "asset_name"],
            "currency": ["í†µí™”", "currency"],
            "market": ["ì‹œì¥", "ì‹œì¥êµ¬ë¶„", "market"],
            "asset_type": ["ìì‚°ìœ í˜•", "asset_type"],
        }
    else:
        aliases = {
            "account_name": ["ê³„ì¢Œëª…", "account", "account_name"],
            "transaction_date": ["ì§€ê¸‰ì¼ì", "ê±°ë˜ì¼", "transaction_date"],
            "ticker": ["í‹°ì»¤", "ì¢…ëª©ì½”ë“œ", "ticker"],
            "asset_name": ["ì¢…ëª©ëª…", "ìì‚°ëª…", "asset_name"],
            "market": ["ì‹œì¥êµ¬ë¶„", "ì‹œì¥", "market"],
            "currency": ["í†µí™”", "currency"],
            "dividend_net": ["ë°°ë‹¹ê¸ˆì„¸í›„", "ë°°ë‹¹ê¸ˆ(ì„¸í›„)", "dividend_net"],
            "dividend_gross": ["ë°°ë‹¹ê¸ˆì„¸ì „", "ë°°ë‹¹ê¸ˆ(ì„¸ì „)", "dividend_gross"],
        }

    mapped_df, missing = _map_columns(raw_df, aliases)
    required_fields = [
        "account_name",
        "transaction_date",
        "ticker",
    ]
    if import_type == "ë§¤ë§¤ ë‚´ì—­":
        required_fields += ["trade_type", "quantity", "price"]
    else:
        required_fields += ["asset_name", "market", "currency", "dividend_net", "dividend_gross"]

    missing_required = [field for field in required_fields if field in missing]
    if missing_required:
        st.error(f"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_required)}")
        return

    st.markdown("### âœ… ì—…ë¡œë“œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(mapped_df.head(10), width='stretch')

    auto_cash = False
    if import_type == "ë§¤ë§¤ ë‚´ì—­":
        auto_cash = st.checkbox("BUY/SELL ì‹œ CASH ìë™ ë°˜ì˜", value=True)

    if import_type == "ë§¤ë§¤ ë‚´ì—­":
        prepared, errors = _prepare_trade_rows(mapped_df, user_id)
    else:
        prepared, errors = _prepare_dividend_rows(mapped_df, user_id)

    if errors:
        st.error("ì—…ë¡œë“œ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì–´ ì „ì²´ ì—…ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.dataframe(pd.DataFrame({"ì˜¤ë¥˜": errors}))
        return

    st.success("âœ… ëª¨ë“  í–‰ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if st.button("ì—…ë¡œë“œ ì‹¤í–‰"):
        try:
            inserted_count, created_assets = _execute_upload(prepared, auto_cash)
        except Exception as exc:
            st.error(f"ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
            return

        st.success(f"ì´ {inserted_count}ê±´ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if created_assets:
            unique_assets = sorted(set(created_assets))
            st.warning(
                "ë‹¤ìŒ ìì‚°ì„ ì‹ ê·œ ë“±ë¡í•˜ê³  ê±°ë˜ë‚´ì—­ì„ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. "
                "ê°€ê²© ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ price_sourceë¥¼ ì—…ë°ì´íŠ¸í•´ ì£¼ì„¸ìš”: "
                + ", ".join(unique_assets)
            )
        st.info("ì—…ë¡œë“œ ì™„ë£Œ í›„ ê±°ë˜ ë‚´ì—­ ë° ìŠ¤ëƒ…ìƒ·ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
