# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ê³¼ ì¡°íšŒ ë¡œì§ë§Œ ë‹´ë‹¹í•©ë‹ˆë‹¤. UI ì½”ë“œëŠ” ë„£ì§€ ì•ŠìŠµë‹ˆë‹¤.
import os
import pandas as pd
import streamlit as st
from supabase import create_client
from dotenv import load_dotenv
from FinanceDataReader import data as fdr
import yfinance as yf
import numpy as np
from datetime import datetime, date

# -------------------------------------------------------------------
# 1. Supabase ì—°ê²° ì´ˆê¸°í™”
# -------------------------------------------------------------------
load_dotenv()

@st.cache_resource
def init_connection():
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY")
    if not url or not key:
        st.error("âŒ Supabase í™˜ê²½ ë³€ìˆ˜(SUPABASE_URL, SUPABASE_KEY)ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    return create_client(url, key)

# -------------------------------------------------------------------
# 2. ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜ (ìºì‹± ì ìš©)
# -------------------------------------------------------------------
@st.cache_data(ttl=600)
def fetch_data(table_name):
    """í…Œì´ë¸” ë˜ëŠ” ë·°(View)ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    supabase = init_connection()
    if not supabase: return pd.DataFrame()

    try:
        response = supabase.table(table_name).select("*").execute()
        df = pd.DataFrame(response.data)

        # ğŸ“Œ [í•µì‹¬] 'transactions' í…Œì´ë¸”ì˜ ë‚ ì§œ ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        if table_name == 'transactions' and 'transaction_date' in df.columns:
            df['transaction_date'] = pd.to_datetime(df['transaction_date'], errors='coerce')
        
        return df
    except Exception as e:
        st.error(f"âš ï¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ({table_name}): {e}")
        return pd.DataFrame()
    
# -------------------------------------------------------------------
# 3. í™˜ìœ¨ ì¡°íšŒ í•¨ìˆ˜ (ìºì‹± ì ìš©)
# -------------------------------------------------------------------
@st.cache_data(ttl=3600)
def fetch_usd_exchange_rate():
    """
    [Warning í•´ê²°] ìµœì‹  FinanceDataReader ê¶Œì¥ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ USD/KRW í™˜ìœ¨ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        df_rate = fdr.DataReader('FRED:DEXKOUS', start='2025-01-01')
        
        if df_rate is not None and not df_rate.empty:
            return df_rate.iloc[-1]['DEXKOUS']
        return 1300.0
    except Exception:
        return 1300.0
    
# -------------------------------------------------------------------
# 4. ë°ì´í„° ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (ì‹ ê·œ: í˜„ì¬ê°€ ì—…ë°ì´íŠ¸)
# -------------------------------------------------------------------
def fetch_current_prices(df_assets):
    """
    yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ìì‚°ì˜ í˜„ì¬ê°€ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    if df_assets.empty or 'ticker' not in df_assets.columns:
        return df_assets

    tickers = df_assets['ticker'].dropna().unique().tolist()
    current_prices = {}
    
    for ticker in tickers:
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="1d")
            if not hist.empty:
                current_prices[ticker] = hist['Close'].iloc[-1]
            else:
                current_prices[ticker] = None
        except Exception:
            current_prices[ticker] = None

    price_df = pd.DataFrame(
        list(current_prices.items()), 
        columns=['ticker', 'current_price_fetched']
    )
    
    df_assets = pd.merge(df_assets, price_df, on='ticker', how='left')
    df_assets['current_price'] = df_assets['current_price_fetched'].combine_first(df_assets['current_price'])
    df_assets = df_assets.drop(columns=['current_price_fetched'], errors='ignore')

    return df_assets

# -------------------------------------------------------------------
# 5. ì¡°íšŒìš© ë£©ì—… ë°ì´í„° (Asset, Account, Code) ë¡œë“œ í•¨ìˆ˜
# -------------------------------------------------------------------
@st.cache_data(ttl=3600)
def get_lookup_data():
    """ë“œë¡­ë‹¤ìš´ ì„ íƒì§€(ë£©ì—… ë°ì´í„°)ë¥¼ ë¯¸ë¦¬ ë¡œë“œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
    
    df_assets = fetch_data("assets")
    required_asset_cols = ['id', 'name_kr', 'asset_type', 'currency', 'market']
    if not df_assets.empty and all(c in df_assets.columns for c in required_asset_cols):
        asset_lookup = df_assets[required_asset_cols].copy()
    else:
        asset_lookup = pd.DataFrame(columns=required_asset_cols)

    asset_name_to_id = asset_lookup.set_index('name_kr')['id'].to_dict() if not asset_lookup.empty else {}
    asset_id_to_name = asset_lookup.set_index('id')['name_kr'].to_dict() if not asset_lookup.empty else {}

    df_accounts = fetch_data("accounts")
    required_account_cols = ['id', 'name', 'brokerage', 'type', 'owner']
    if not df_accounts.empty and all(c in df_accounts.columns for c in required_account_cols):
        account_lookup = df_accounts[required_account_cols].copy()
        account_lookup['display_name'] = account_lookup['name'] + ' (' + account_lookup['brokerage'] + ')'
    else:
        account_lookup = pd.DataFrame(columns=required_account_cols + ['display_name'])

    account_id_to_name_db = account_lookup.set_index('id')['name'].to_dict() if not account_lookup.empty else {}
    account_name_to_id_db = account_lookup.set_index('name')['id'].to_dict() if not account_lookup.empty else {}
    account_name_to_id_display = account_lookup.set_index('display_name')['id'].to_dict() if not account_lookup.empty else {}
    account_id_to_name_display = account_lookup.set_index('id')['display_name'].to_dict() if not account_lookup.empty else {}

    is_asset_empty = asset_lookup.empty
    is_account_empty = account_lookup.empty

    code_map = {
        'asset_type': {'stock': 'ì£¼ì‹', 'stock': 'ì£¼ì‹', 'cash': 'í˜„ê¸ˆ', 'fund': 'í€ë“œ', 
                       'bond': 'ì±„ê¶Œ', 'gold': 'ê¸ˆ', 'etf': 'ETF'},
        'currency': {'won': 'í•œí™”', 'usd': 'ë‹¬ëŸ¬', 'jpy': 'ì—”í™”', '': 'ê¸°íƒ€'},
        'market': {'korea': 'í•œêµ­', 'us': 'ë¯¸êµ­', 'jp': 'ì¼ë³¸', '': 'ê¸°íƒ€'},
    }
    
    code_lookup = {
        'trade_types': ["BUY", "SELL"],
        'asset_types': list(code_map['asset_type'].values()),
        'currencies': list(code_map['currency'].values()),
        'markets': list(code_map['market'].values()),
        'account_owners': account_lookup['owner'].dropna().unique().tolist() if not is_account_empty else ["ìŠ¹ì—½", "ë¯¼í¬"],
        'account_types': account_lookup['type'].dropna().unique().tolist() if not is_account_empty else ["ì¼ë°˜", "ISA", "DC", "IRP", "ì—°ê¸ˆì €ì¶•"],
        'type_to_kr': {'stock': 'ì£¼ì‹', 'stock': 'ì£¼ì‹', 'cash': 'í˜„ê¸ˆ', 'fund': 'í€ë“œ', 
                       'bond': 'ì±„ê¶Œ', 'gold': 'ê¸ˆ', 'etf': 'ETF'}, 
        'code_map': code_map,
    }

    kr_to_code_map = {
        key: {v: k for k, v in value.items()} 
        for key, value in code_map.items()
    }

    return {
        'asset_id_to_name': asset_id_to_name,
        'asset_name_to_id': asset_name_to_id,
        'account_id_to_name_display': account_id_to_name_display,
        'account_name_to_id_display': account_name_to_id_display,
        'account_id_to_name_db': account_id_to_name_db,
        'account_name_to_id_db': account_name_to_id_db,
        'kr_to_code_map': kr_to_code_map,
        'codes': code_lookup,
        'asset_lookup_df': asset_lookup,
        'account_lookup_df': account_lookup
    }

# -------------------------------------------------------------------
# 6. ğŸ“Š [ì‹ ê·œ] Transactions ê¸°ë°˜ asset_summary ì¬ê³„ì‚° í•¨ìˆ˜
# -------------------------------------------------------------------
def recalculate_asset_summary():
    """
    transactions í…Œì´ë¸”ì— ê¸°ë°˜í•˜ì—¬ asset_summary í…Œì´ë¸”ì˜ ë‚´ìš©ì„ ì¬ê³„ì‚°í•˜ê³  ë®ì–´ì”ë‹ˆë‹¤.
    asset_summaryëŠ” ì´ì œ ë·°ê°€ ì•„ë‹Œ í…Œì´ë¸”ì…ë‹ˆë‹¤.
    """
    supabase = init_connection()
    if not supabase: return False

    SUMMARY_TABLE_NAME = "asset_summary"
    
    try:
        st.info("ğŸ”„ 'transactions' ê¸°ë°˜ìœ¼ë¡œ 'asset_summary' í…Œì´ë¸”ì„ ì¬ê³„ì‚°í•©ë‹ˆë‹¤.")
        
        # 1. ê³„ì‚°ì— í•„ìš”í•œ ê¸°ì´ˆ ë°ì´í„° ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
        df_transactions = fetch_data("transactions")
        df_assets = fetch_data("assets")
        df_accounts = fetch_data("accounts")

        if df_transactions.empty or df_assets.empty:
            st.warning("âš ï¸ ê±°ë˜ ê¸°ë¡(transactions) ë˜ëŠ” ìì‚° ì •ë³´(assets)ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # 2. ë°ì´í„° ë³‘í•© (Merge)
        # transactions + assets (ìì‚° ì •ë³´) ë³‘í•©
        df_merged = pd.merge(df_transactions, 
                             df_assets[['id', 'ticker', 'name_kr', 'asset_type', 'currency', 'current_price']], 
                             left_on='asset_id', 
                             right_on='id', 
                             suffixes=('', '_asset'), 
                             how='left')
        
        # transactions + accounts (ê³„ì¢Œ ID) ë³‘í•©
        df_merged = pd.merge(df_merged, 
                             df_accounts[['id', 'account_id']], 
                             left_on='account_name', 
                             right_on='name', 
                             suffixes=('', '_account'), 
                             how='left')
        
        # account_id ì»¬ëŸ¼ ì •ë¦¬ (DBì— account_idê°€ ì—†ìœ¼ë¯€ë¡œ ìˆ˜ë™ ë§¤í•‘ ë¡œì§ í•„ìš”)
        # ğŸ“Œ 'account_name'ì„ ì´ìš©í•˜ì—¬ 'accounts' í…Œì´ë¸”ì—ì„œ 'id'ë¥¼ ê°€ì ¸ì™€ 'account_id'ë¡œ ì‚¬ìš©
        account_name_to_id = df_accounts.set_index('name')['id'].to_dict()
        df_merged['account_id'] = df_merged['account_name'].map(account_name_to_id)
        
        # í•„ìš”í•œ ìˆ«ìí˜• ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜ (ê³„ì‚°ì˜ ì •í™•ì„± í™•ë³´)
        df_merged['quantity'] = pd.to_numeric(df_merged['quantity'], errors='coerce')
        df_merged['price'] = pd.to_numeric(df_merged['price'], errors='coerce')
        df_merged['current_price'] = pd.to_numeric(df_merged['current_price'], errors='coerce')
        
        # 3. ìì‚° ìš”ì•½ í•µì‹¬ ê³„ì‚° ë¡œì§
        
        # 3-1. ìˆ˜ëŸ‰(Total Quantity) ë° ì´ ë§¤ìˆ˜ ê¸ˆì•¡(Total Purchase Amount) ê³„ì‚°
        # BUY: +quantity, SELL: -quantity
        df_merged['signed_quantity'] = df_merged.apply(
            lambda row: row['quantity'] if row['trade_type'] == 'BUY' else -row['quantity'], 
            axis=1
        )
        # ì´ ë§¤ìˆ˜ ê¸ˆì•¡: BUYì¼ ë•Œë§Œ ê³„ì‚°
        df_merged['purchase_amount'] = df_merged.apply(
            lambda row: row['quantity'] * row['price'] if row['trade_type'] == 'BUY' else 0, 
            axis=1
        )

        # ê·¸ë£¹í™” ê¸°ì¤€: asset_idì™€ account_id
        df_summary_base = df_merged.groupby(['asset_id', 'account_id']).agg(
            total_quantity=('signed_quantity', 'sum'), # ìµœì¢… ë³´ìœ  ìˆ˜ëŸ‰
            total_purchase_amount=('purchase_amount', 'sum') # ì´ ë§¤ìˆ˜ ê¸ˆì•¡
        ).reset_index()

        # 3-2. í‰ê·  ë§¤ìˆ˜ ê°€ê²© ë° í‰ê°€ ê¸ˆì•¡ ê³„ì‚°
        # total_quantityê°€ 0ì¸ ê²½ìš°(ì „ëŸ‰ ë§¤ë„), í‰ê·  ë§¤ìˆ˜ ê°€ê²© ê³„ì‚°ì—ì„œ ì œì™¸ (0ìœ¼ë¡œ ì„¤ì •)
        df_summary_base['average_purchase_price'] = np.where(
            df_summary_base['total_quantity'] > 0,
            df_summary_base['total_purchase_amount'] / df_summary_base['total_quantity'],
            0.0 # ìˆ˜ëŸ‰ì´ 0ì´ë©´ í‰ê·  ë§¤ìˆ˜ ê°€ê²©ì€ 0
        )
        
        # ìì‚° ì •ë³´ (ticker, current_price ë“±)ë¥¼ ë‹¤ì‹œ ë³‘í•©
        df_summary_final = pd.merge(df_summary_base, 
                                     df_assets[['id', 'ticker', 'name_kr', 'asset_type', 'currency', 'current_price']],
                                     left_on='asset_id', 
                                     right_on='id', 
                                     how='left')
        
        # 3-3. í‰ê°€ ê´€ë ¨ ì§€í‘œ ê³„ì‚°
        # í˜„ì¬ í‰ê°€ ê°€ê²© (current_valuation_price): current_priceë¥¼ ì‚¬ìš©
        df_summary_final['current_valuation_price'] = df_summary_final['current_price']
        
        # ì´ í‰ê°€ ê¸ˆì•¡ (total_valuation_amount)
        df_summary_final['total_valuation_amount'] = (
            df_summary_final['total_quantity'] * df_summary_final['current_valuation_price']
        )
        
        # í‰ê°€ ì†ìµ (unrealized_pnl)
        df_summary_final['unrealized_pnl'] = (
            df_summary_final['total_valuation_amount'] - df_summary_final['total_purchase_amount']
        )
        
        # ìˆ˜ìµë¥  (unrealized_return_rate)
        df_summary_final['unrealized_return_rate'] = np.where(
            df_summary_final['total_purchase_amount'] > 0,
            (df_summary_final['unrealized_pnl'] / df_summary_final['total_purchase_amount']) * 100,
            0.0 # ë§¤ìˆ˜ ê¸ˆì•¡ì´ 0ì´ë©´ ìˆ˜ìµë¥ ë„ 0
        )

        # 4. ìµœì¢… DataFrame ì •ë¦¬ ë° í•„í„°ë§
        # ë³´ìœ  ìˆ˜ëŸ‰ì´ 0ë³´ë‹¤ í° ê²½ìš°ë§Œ í•„í„°ë§ (ì™„ì „ ë§¤ë„ëœ ì¢…ëª© ì œì™¸)
        df_new_summary = df_summary_final[df_summary_final['total_quantity'] > 0].copy()
        
        # asset_summary í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì»¬ëŸ¼ëª… ì •ë¦¬
        df_new_summary = df_new_summary.rename(columns={'id_x': 'id'}) # id_xê°€ transactionsì˜ idì˜€ë‹¤ë©´
        
        # í•„ìš”í•œ ìµœì¢… ì»¬ëŸ¼ ì„ íƒ (DB í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•´ì•¼ í•¨)
        # ìŠ¤í‚¤ë§ˆ: asset_id, account_id, ticker, name_kr, currency, asset_type, total_quantity, 
        #         current_valuation_price, total_purchase_amount, total_valuation_amount, 
        #         average_purchase_price, unrealized_pnl, unrealized_return_rate
        final_cols = [
            'asset_id', 'account_id', 'ticker', 'name_kr', 'currency', 'asset_type', 
            'total_quantity', 'current_valuation_price', 'total_purchase_amount', 
            'total_valuation_amount', 'average_purchase_price', 'unrealized_pnl', 
            'unrealized_return_rate'
        ]
        
        # ë°ì´í„° íƒ€ì… ì¡°ì • (Postgres numeric/bigintì— ë§ì¶”ê¸° ìœ„í•´)
        for col in ['total_quantity', 'current_valuation_price', 'total_purchase_amount', 
                    'total_valuation_amount', 'average_purchase_price', 'unrealized_pnl']:
            df_new_summary[col] = pd.to_numeric(df_new_summary[col], errors='coerce').round(4)
        df_new_summary['unrealized_return_rate'] = pd.to_numeric(df_new_summary['unrealized_return_rate'], errors='coerce').round(8)
        
        df_new_summary = df_new_summary[final_cols]

        # 5. DBì— ì €ì¥ (Delete í›„ Upsert)
        
        # ğŸ“Œ [í•´ê²°] asset_summaryê°€ ì´ì œ í…Œì´ë¸”ì´ë¯€ë¡œ DELETE ëª…ë ¹ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.
        # ê¸°ì¡´ ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚­ì œí•˜ì—¬ ì¬ê³„ì‚°ëœ ìƒˆ ë°ì´í„°ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
        # 'asset_id' != 0 ì¡°ê±´ì€ í•„ìš” ì—†ì„ ìˆ˜ë„ ìˆì§€ë§Œ, ì•ˆì „ì„ ìœ„í•´ ìœ ì§€í•©ë‹ˆë‹¤.
        supabase.table(SUMMARY_TABLE_NAME).delete().neq('asset_id', 0).execute()  # ê¸°ì¡´ ìš”ì•½ ë°ì´í„° ì „ì²´ ì‚­ì œ
        
        new_records = df_new_summary.where(pd.notnull(df_new_summary), None).to_dict('records')

        # ğŸ“Œ ë°ì´í„° íƒ€ì… í´ë¦¬ë‹: ì •ìˆ˜í˜• ì‹¤ìˆ˜(38.0)ë¥¼ ì •ìˆ˜(38)ë¡œ ë³€í™˜ (bigint ì—ëŸ¬ ë°©ì§€)
        cleaned_records = []
        for record in new_records:
            cleaned_record = {}
            for key, value in record.items():
                if value is None or pd.isna(value):
                    cleaned_record[key] = None
                elif isinstance(value, (float, np.floating, np.float64, np.float32)):
                    if float(value).is_integer():
                        cleaned_record[key] = int(value)
                    else:
                        cleaned_record[key] = float(value)
                else:
                    cleaned_record[key] = value
            cleaned_records.append(cleaned_record)
            
        # ğŸ“Œ ê³„ì‚°ëœ ìƒˆ ë°ì´í„° ì‚½ì… (asset_idê°€ Primary Key ì—­í• ì„ í•˜ë¯€ë¡œ upsert ì‚¬ìš©)
        supabase.table(SUMMARY_TABLE_NAME).upsert(cleaned_records).execute()
        
        st.success("âœ… asset_summary í…Œì´ë¸” ì¬ê³„ì‚° ë° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        st.cache_data.clear() # ìºì‹œ ì´ˆê¸°í™”í•˜ì—¬ ëŒ€ì‹œë³´ë“œì—ì„œ ìµœì‹  ë°ì´í„° ë¡œë“œ ìœ ë„
        return True
    
    except Exception as e:
        st.error(f"âŒ asset_summary ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
        import traceback
        st.error(traceback.format_exc())
        st.warning("DBì—ì„œ 'asset_summary' ë·°ë¥¼ ì‚­ì œí•˜ê³ , ë™ì¼í•œ ì´ë¦„ì˜ í…Œì´ë¸”ë¡œ ìƒì„±í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return False

# -------------------------------------------------------------------
# 7. ë°ì´í„° ë³€ê²½ í•¨ìˆ˜ (ì €ì¥/ìˆ˜ì •/ì‚­ì œ)
# -------------------------------------------------------------------
def update_data(table_name, df_changes):
    """
    Supabase í…Œì´ë¸”ì— ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    transactions í…Œì´ë¸”ì€ INSERT / UPDATEë¥¼ ë¶„ë¦¬í•˜ì—¬
    id = NULL ë¬¸ì œë¥¼ êµ¬ì¡°ì ìœ¼ë¡œ ì°¨ë‹¨í•©ë‹ˆë‹¤.
    """

    supabase = init_connection()
    if not supabase:
        return False

    PK_COL = 'id'

    try:
        lookup = get_lookup_data()

        # =====================================================
        # 1ï¸âƒ£ transactions ì „ì²˜ë¦¬ (ìì‚° / ê³„ì¢Œ ë³€í™˜)
        # =====================================================
        if table_name == 'transactions':

            if 'name_kr' in df_changes.columns:
                df_changes['asset_id'] = df_changes['name_kr'].map(
                    lookup['asset_name_to_id']
                )
                df_changes.drop(columns=['name_kr'], inplace=True, errors='ignore')

            if 'account_display_name' in df_changes.columns:
                df_changes['account_id'] = df_changes['account_display_name'].map(
                    lookup['account_name_to_id_display']
                )
                df_changes['account_name'] = df_changes['account_id'].map(
                    lookup['account_id_to_name_db']
                )
                df_changes.drop(
                    columns=['account_display_name'], inplace=True, errors='ignore'
                )

        # =====================================================
        # 2ï¸âƒ£ DataFrame â†’ dict ë³€í™˜ (NaN â†’ None)
        # =====================================================
        records = (
            df_changes
            .where(pd.notnull(df_changes), None)
            .to_dict('records')
        )

        insert_rows = []
        update_rows = []

        # =====================================================
        # 3ï¸âƒ£ INSERT / UPDATE ë¶„ë¦¬ (ğŸ”¥ í•µì‹¬)
        # =====================================================
        for record in records:
            cleaned = {}

            for key, value in record.items():
                if value is None or pd.isna(value):
                    cleaned[key] = None

                elif isinstance(value, (pd.Timestamp, datetime, date)):
                    if key == 'transaction_date':
                        cleaned[key] = value.strftime('%Y-%m-%d %H:%M:%S+00')
                    else:
                        cleaned[key] = value.strftime('%Y-%m-%d')

                elif isinstance(value, (float, np.floating)):
                    cleaned[key] = int(value) if float(value).is_integer() else float(value)

                elif isinstance(value, (int, np.integer)):
                    cleaned[key] = int(value)

                elif isinstance(value, np.bool_):
                    cleaned[key] = bool(value)

                else:
                    cleaned[key] = value

            # id ê¸°ì¤€ìœ¼ë¡œ ë¶„ê¸°
            if cleaned.get(PK_COL) is None:
                cleaned.pop(PK_COL, None)  # INSERT ì‹œ id ì œê±°
                insert_rows.append(cleaned)
            else:
                update_rows.append(cleaned)

        # =====================================================
        # ğŸ” ë””ë²„ê¹… ì¶œë ¥
        # =====================================================
        print("ğŸŸ¢ INSERT rows", insert_rows[-5:-1])
        print("ğŸŸ¡ UPDATE rows", update_rows[-5:-1])

        # =====================================================
        # 4ï¸âƒ£ DB ë°˜ì˜
        # =====================================================
        if insert_rows:
            supabase.table(table_name).insert(insert_rows).execute()

        for row in update_rows:
            supabase.table(table_name) \
                .update(row) \
                .eq(PK_COL, row[PK_COL]) \
                .execute()

        st.cache_data.clear()

        if table_name == 'transactions':
            st.info("ğŸ”„ ê±°ë˜ ë‚´ì—­ ì €ì¥ ì™„ë£Œ â†’ asset_summary ì¬ê³„ì‚°")
            recalculate_asset_summary()
        else:
            st.success("âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ")

        return True

    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


# -------------------------------------------------------------------
# 8. ğŸ“Œ [ì‹ ê·œ] ë°ì´í„° ì‚­ì œ í•¨ìˆ˜ êµ¬í˜„
# -------------------------------------------------------------------
def delete_data(table_name, record_id):
    """
    íŠ¹ì • ë ˆì½”ë“œë¥¼ DBì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤.
    
    Args:
        table_name (str): í…Œì´ë¸”ëª…
        record_id (int/str): ì‚­ì œí•  ë ˆì½”ë“œì˜ ID (PK)
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    supabase = init_connection()
    if not supabase:
        st.error("âŒ DB ì—°ê²° ì‹¤íŒ¨")
        return False
    
    try:
        # Supabase delete API ì‚¬ìš© (id ì»¬ëŸ¼ ê¸°ì¤€)
        response = supabase.table(table_name).delete().eq('id', record_id).execute()
        
        # ìºì‹œ ì´ˆê¸°í™”
        st.cache_data.clear()
        
        # ğŸ“Š transactions í…Œì´ë¸” ì‚­ì œ í›„ asset_summary ìë™ ì¬ê³„ì‚°
        if table_name == 'transactions':
            recalculate_asset_summary()
        
        return True
        
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨ (ID: {record_id}): {e}")
        return False

# -------------------------------------------------------------------
# 9. ğŸ”® [í–¥í›„ í™•ì¥ìš©] ì¼ë³„ ìŠ¤ëƒ…ìƒ· ìë™ ìƒì„± í•¨ìˆ˜
# -------------------------------------------------------------------
def create_daily_snapshot(snapshot_date=None):
    """
    íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ account_snapshots í…Œì´ë¸”ì— ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        snapshot_date (str): 'YYYY-MM-DD' í˜•ì‹. Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    from datetime import datetime
    
    supabase = init_connection()
    if not supabase:
        return False
    
    if snapshot_date is None:
        snapshot_date = datetime.now().strftime('%Y-%m-%d')
    
    try:
        # asset_summary ë°ì´í„° ë¡œë“œ
        df_summary = fetch_data("asset_summary")
        if df_summary.empty:
            st.warning("âš ï¸ asset_summaryê°€ ë¹„ì–´ìˆì–´ ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ìŠ¤ëƒ…ìƒ· ë°ì´í„° ìƒì„± (account_snapshots ìŠ¤í‚¤ë§ˆì— ë§ì¶¤)
        snapshots = df_summary.copy()
        snapshots['date'] = snapshot_date
        
        # ì»¬ëŸ¼ ë§¤í•‘
        snapshots = snapshots.rename(columns={
            'total_quantity': 'quantity',
            'current_valuation_price': 'valuation_price',
            'average_purchase_price': 'purchase_price',
            'total_valuation_amount': 'valuation_amount',
            'total_purchase_amount': 'purchase_amount'
        })
        
        # cost ì»¬ëŸ¼ ì¶”ê°€ (ê¸°ë³¸ê°’ 0)
        snapshots['cost'] = 0
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        final_cols = [
            'account_id', 'asset_id', 'date', 'currency', 
            'quantity', 'valuation_price', 'purchase_price',
            'valuation_amount', 'purchase_amount', 'cost'
        ]
        
        snapshots_final = snapshots[final_cols].copy()
        
        # DBì— ì‚½ì…
        records = snapshots_final.where(pd.notnull(snapshots_final), None).to_dict('records')
        supabase.table("account_snapshots").upsert(records).execute()
        
        st.success(f"âœ… {snapshot_date} ìŠ¤ëƒ…ìƒ·ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ {len(snapshots_final)}ê°œ)")
        return True
        
    except Exception as e:
        st.error(f"âŒ ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹¤íŒ¨: {e}")
        return False